{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis writeup revisited\n",
    "\n",
    "Author: Luis Eduardo San Martin\n",
    "\n",
    "This writeup is a revision of the former analysis writeup I submitted for assignment 3.\n",
    "\n",
    "## The problem\n",
    "\n",
    "Once you've set up the improved pipeline, you should apply it to solve the following problem:\n",
    "\n",
    "The problem is to predict if a project on donorschoose will not get fully funded within 60 days of posting. This prediction is being done at the time of posting so you can only use data available to you at that time. The data is a file that has one row for each project posted with a column for \"date_posted\" (the date the project was posted) and a column for \"datefullyfunded\" (the date the project was fully funded - assumption for this assignment is that all projects were fully funded eventually). The task is to predict if a project on donorschoose will not get fully funded within 60 days of posting.\n",
    "\n",
    "The data spans Jan 1, 2012 to Dec 31, 2013. You should have your validation/test set be a rolling window of 6 months (which should give you three test sets). The training sets should be everything from 1/1/12 to the beginning of the test set.\n",
    "\n",
    "The code should produce a table with results across train test splits over time and performance metrics (baseline, precision and recall at different thresholds 1%, 2%, 5%, 10%, 20%, 30%, 50% and AUC_ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My (new) solution\n",
    "\n",
    "For this solution, I'll rely on the functions I wrote for my Machine Learning pipeline.\n",
    "\n",
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>5/2/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/7/12</td>\n",
       "      <td>4/18/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/30/12</td>\n",
       "      <td>4/15/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/11/12</td>\n",
       "      <td>12/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/8/13</td>\n",
       "      <td>3/25/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00049ec8ca1f2d08cb13cab31b0b85ec</td>\n",
       "      <td>7149611553c700de9a6099f8a9ce598b</td>\n",
       "      <td>462a5fd93cf9fb5d41eecfd2ea860b19</td>\n",
       "      <td>2.621150e+11</td>\n",
       "      <td>42.740157</td>\n",
       "      <td>-84.525821</td>\n",
       "      <td>Lansing</td>\n",
       "      <td>MI</td>\n",
       "      <td>urban</td>\n",
       "      <td>Lansing School District</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>475.85</td>\n",
       "      <td>15.0</td>\n",
       "      <td>f</td>\n",
       "      <td>11/30/12</td>\n",
       "      <td>2/26/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0004d2fdbb571237fa53a97e7691440b</td>\n",
       "      <td>926671e209fb977bd5123145c1848ad1</td>\n",
       "      <td>1a994778027ab086dc58ec3b47f74ff0</td>\n",
       "      <td>4.047200e+10</td>\n",
       "      <td>33.059361</td>\n",
       "      <td>-112.037727</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>rural</td>\n",
       "      <td>Maricopa Unif Sch District 20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>390.65</td>\n",
       "      <td>37.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3/26/13</td>\n",
       "      <td>4/17/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0004ee26667e751dd51384eb9f30c72e</td>\n",
       "      <td>abe4dabb7864f4c548d230cf9070e03f</td>\n",
       "      <td>8409f70bcd81bc06e4b9efca68eed8f6</td>\n",
       "      <td>6.280501e+10</td>\n",
       "      <td>37.761958</td>\n",
       "      <td>-122.193209</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Oakland Unified School Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>3877.20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2/28/13</td>\n",
       "      <td>3/10/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0006a31d45f8d52d217e7c5b55c11f37</td>\n",
       "      <td>3b5fada1ad0e339acc669829071320c4</td>\n",
       "      <td>c6a033f9349ea70659c1891b119680ed</td>\n",
       "      <td>2.307320e+11</td>\n",
       "      <td>44.096641</td>\n",
       "      <td>-70.191734</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>ME</td>\n",
       "      <td>urban</td>\n",
       "      <td>Lewiston Public Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>838.75</td>\n",
       "      <td>25.0</td>\n",
       "      <td>f</td>\n",
       "      <td>8/21/13</td>\n",
       "      <td>9/13/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0008ac907bf237a15a959244205d3ee5</td>\n",
       "      <td>92527a5ac5fe946ed1961fb2e1de8cc5</td>\n",
       "      <td>23e34f5d2e2940684269cffe35741598</td>\n",
       "      <td>6.271800e+10</td>\n",
       "      <td>34.381832</td>\n",
       "      <td>-118.531837</td>\n",
       "      <td>Newhall</td>\n",
       "      <td>CA</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Newhall School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1477.44</td>\n",
       "      <td>24.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/3/12</td>\n",
       "      <td>11/3/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0009bc936fed4728d5fd86d92ee3cec1</td>\n",
       "      <td>66b77e507a30a5fbbcb4f7631c5ccc75</td>\n",
       "      <td>af67655269d03992889a8db7fe0cf83d</td>\n",
       "      <td>6.072000e+10</td>\n",
       "      <td>37.263773</td>\n",
       "      <td>-121.996427</td>\n",
       "      <td>Saratoga</td>\n",
       "      <td>CA</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Campbell Union School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Other</td>\n",
       "      <td>low poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>194.11</td>\n",
       "      <td>25.0</td>\n",
       "      <td>f</td>\n",
       "      <td>7/29/13</td>\n",
       "      <td>11/26/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000a6dcbb21ec643daf74ed28991d29c</td>\n",
       "      <td>93e0a37fca3cd7c9c32a535673c48af4</td>\n",
       "      <td>7e28905e0126e37d9b747e92c5fcf44d</td>\n",
       "      <td>2.926850e+11</td>\n",
       "      <td>38.535275</td>\n",
       "      <td>-90.464493</td>\n",
       "      <td>Fenton</td>\n",
       "      <td>MO</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Rockwood School District R6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>714.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6/22/13</td>\n",
       "      <td>10/17/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000a981e6bd61c489bbebc237f7b6a0d</td>\n",
       "      <td>a886a532c21f83b0c30571208636dc0e</td>\n",
       "      <td>c995de8108ac314637e1c869f81af766</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.922711</td>\n",
       "      <td>-87.692965</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Fullerton Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>523.27</td>\n",
       "      <td>700.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/22/13</td>\n",
       "      <td>2/28/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000b238b8c85214d58683b13398fd058</td>\n",
       "      <td>439f1e081199a89540cbf69866cfd182</td>\n",
       "      <td>685d2471561270abe3820d947fbbe3e9</td>\n",
       "      <td>6.225000e+10</td>\n",
       "      <td>33.773256</td>\n",
       "      <td>-118.183848</td>\n",
       "      <td>Long Beach</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Long Beach Unified School Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>Gym &amp; Fitness</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1108.94</td>\n",
       "      <td>809.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/27/13</td>\n",
       "      <td>11/29/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000b574223b4f491c7de7bccae88b51d</td>\n",
       "      <td>5003eacb7e6311d01177c275c633768a</td>\n",
       "      <td>87e515cc802d93213adfb963ef8de30e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.813916</td>\n",
       "      <td>-73.900522</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>677.73</td>\n",
       "      <td>24.0</td>\n",
       "      <td>t</td>\n",
       "      <td>5/28/13</td>\n",
       "      <td>9/6/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000bab2056ba84931f4f5bc72f542e03</td>\n",
       "      <td>10d2de84406c94967bb0f01f57ba980f</td>\n",
       "      <td>d0318b91338cd9dd6f18202eebe7c9c2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.013238</td>\n",
       "      <td>-81.391606</td>\n",
       "      <td>St Augustine</td>\n",
       "      <td>FL</td>\n",
       "      <td>suburban</td>\n",
       "      <td>St Johns Co School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>165.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/9/12</td>\n",
       "      <td>1/22/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000be0b57987d6c29d650a88eac2961b</td>\n",
       "      <td>ae7b6b599922817b2e0cb9f96354297e</td>\n",
       "      <td>922a11f9ab72afebccf5b9391191e1bd</td>\n",
       "      <td>2.102490e+11</td>\n",
       "      <td>37.803213</td>\n",
       "      <td>-85.987333</td>\n",
       "      <td>Vine Grove</td>\n",
       "      <td>KY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Hardin Co School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Health &amp; Life Science</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>481.18</td>\n",
       "      <td>120.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/26/12</td>\n",
       "      <td>5/17/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000d3ead6b648ba31043bb6376e6342d</td>\n",
       "      <td>3dd9af5310c77541f5b65cf190cec338</td>\n",
       "      <td>8018b1c81de3aede5363afabcf32b17c</td>\n",
       "      <td>4.088000e+10</td>\n",
       "      <td>32.228378</td>\n",
       "      <td>-110.963287</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>urban</td>\n",
       "      <td>Tucson Unified School Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>265.13</td>\n",
       "      <td>53.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/15/13</td>\n",
       "      <td>3/11/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000e6a13fd69bf0e426403b1d5da0e99</td>\n",
       "      <td>1ad348085983de6a0f1fe6a37779f7f2</td>\n",
       "      <td>82571bc4db2e4cd846e3c50eeceeb176</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.182137</td>\n",
       "      <td>-118.424728</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>296.68</td>\n",
       "      <td>30.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1/23/12</td>\n",
       "      <td>2/20/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000e964b1e5c911adf700736c43e8f85</td>\n",
       "      <td>27076f8d0ec597bfd5035ef84d6691b0</td>\n",
       "      <td>3870254e36f88935745384ebc06a4caf</td>\n",
       "      <td>1.300120e+11</td>\n",
       "      <td>33.752884</td>\n",
       "      <td>-84.342140</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Atlanta Public Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1098.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/22/12</td>\n",
       "      <td>1/12/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000faa31e276e9e649360949207fa00c</td>\n",
       "      <td>86403b5f04ed07201cd04184ff4c0ced</td>\n",
       "      <td>c86d87fee34b13377658337fa8bf2fc5</td>\n",
       "      <td>2.931440e+11</td>\n",
       "      <td>38.367966</td>\n",
       "      <td>-92.477882</td>\n",
       "      <td>Ft Leonard Wd</td>\n",
       "      <td>MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waynesville School Dist R6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>632.13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/18/12</td>\n",
       "      <td>1/6/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0010040593d5e9699ee45834369ec817</td>\n",
       "      <td>1871e44279646e8d18fa74d29dcfc456</td>\n",
       "      <td>83b74057d63f2da28f3635efeffd61a1</td>\n",
       "      <td>1.707650e+11</td>\n",
       "      <td>40.456921</td>\n",
       "      <td>-88.137198</td>\n",
       "      <td>Paxton</td>\n",
       "      <td>IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paxton-buckley-loda Cusd 10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>221.56</td>\n",
       "      <td>100.0</td>\n",
       "      <td>t</td>\n",
       "      <td>9/4/13</td>\n",
       "      <td>10/27/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00103b0614e31016e5c4cc7d405bbc51</td>\n",
       "      <td>9e4433fb2d3078bc4dcbe2860d05ebf5</td>\n",
       "      <td>b22babfd8fbdfa6b53e4747b74da02dd</td>\n",
       "      <td>4.835850e+11</td>\n",
       "      <td>33.183766</td>\n",
       "      <td>-96.494366</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Princeton Ind School Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1125.40</td>\n",
       "      <td>660.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/10/13</td>\n",
       "      <td>4/2/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00105edf14ebb7f146d6ba2098639bb1</td>\n",
       "      <td>ac1ef23232ddd1597f6fa5b28a171fa5</td>\n",
       "      <td>33b6121da948b2fd67fd78f5935eb793</td>\n",
       "      <td>6.261900e+10</td>\n",
       "      <td>34.050485</td>\n",
       "      <td>-118.020442</td>\n",
       "      <td>El Monte</td>\n",
       "      <td>CA</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Mountain View School District-Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>Special Needs</td>\n",
       "      <td>Special Needs</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>2130.40</td>\n",
       "      <td>30.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/29/12</td>\n",
       "      <td>7/16/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>001096473792e89ccc83e9f6ab01871b</td>\n",
       "      <td>e21c4208e61018ed35aa2bcc392a2d40</td>\n",
       "      <td>7fdffcfd5bea8e0fc99952254a875a72</td>\n",
       "      <td>1.200870e+11</td>\n",
       "      <td>28.155807</td>\n",
       "      <td>-82.532195</td>\n",
       "      <td>Lutz</td>\n",
       "      <td>FL</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Hillsborough Co Pub Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>low poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>715.67</td>\n",
       "      <td>17.0</td>\n",
       "      <td>f</td>\n",
       "      <td>11/19/13</td>\n",
       "      <td>12/19/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00134d14226ef613134712c54211f754</td>\n",
       "      <td>5bce35e3991721b665d33095e9d3aa31</td>\n",
       "      <td>9b62c64683b7c3212f159e13eb41ff5c</td>\n",
       "      <td>1.812720e+11</td>\n",
       "      <td>39.920792</td>\n",
       "      <td>-86.142952</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>urban</td>\n",
       "      <td>Washington Township Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>518.22</td>\n",
       "      <td>27.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3/31/12</td>\n",
       "      <td>7/27/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00136585c0e4a67afaa964403cf9f45b</td>\n",
       "      <td>402cfc6b73dc62f44946bc1c381f6b1c</td>\n",
       "      <td>0793efaeba83d8b5b9d55f5772fac62d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.906952</td>\n",
       "      <td>-77.540756</td>\n",
       "      <td>Tarboro</td>\n",
       "      <td>NC</td>\n",
       "      <td>rural</td>\n",
       "      <td>North Carolina Dept of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>350.69</td>\n",
       "      <td>50.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5/30/12</td>\n",
       "      <td>8/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0013a402fb4cf84e3d60d7a59566dff8</td>\n",
       "      <td>511ec2a1372cd7b9e1af86b1b3de8bff</td>\n",
       "      <td>dbde53d7dbafbbb22ca60f36bb0019a5</td>\n",
       "      <td>6.227101e+10</td>\n",
       "      <td>34.227558</td>\n",
       "      <td>-118.499130</td>\n",
       "      <td>North Hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>836.34</td>\n",
       "      <td>29.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/21/12</td>\n",
       "      <td>3/1/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>001468d419e1ee737f364013334d0c84</td>\n",
       "      <td>ca8d614f79013690baf1a8860be4b754</td>\n",
       "      <td>4157e4e610804d738f2d1a450d36dd3f</td>\n",
       "      <td>1.200180e+11</td>\n",
       "      <td>26.240857</td>\n",
       "      <td>-80.165433</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Broward Co Public Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>Special Needs</td>\n",
       "      <td>Special Needs</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>281.95</td>\n",
       "      <td>60.0</td>\n",
       "      <td>f</td>\n",
       "      <td>8/7/12</td>\n",
       "      <td>9/19/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0014cedcb2d697902c15081ab12deadf</td>\n",
       "      <td>b9e31d1b986c0cf802c9e13869b86cef</td>\n",
       "      <td>1d74e61c912fe4527eb57ac456bcac8a</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.837411</td>\n",
       "      <td>-73.854644</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>Early Development</td>\n",
       "      <td>Applied Learning</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>371.81</td>\n",
       "      <td>30.0</td>\n",
       "      <td>f</td>\n",
       "      <td>9/22/13</td>\n",
       "      <td>12/5/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124946</th>\n",
       "      <td>fff008ba1051b272f9e5218b1c125169</td>\n",
       "      <td>4999b5d89891ff2279c63e8f529f00ea</td>\n",
       "      <td>8803e5495d05529e09083007ac95f58b</td>\n",
       "      <td>4.808090e+11</td>\n",
       "      <td>29.434906</td>\n",
       "      <td>-95.254405</td>\n",
       "      <td>Alvin</td>\n",
       "      <td>TX</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Alvin Ind School District</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>957.15</td>\n",
       "      <td>40.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/9/12</td>\n",
       "      <td>12/22/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124947</th>\n",
       "      <td>fff025ce2682430f72e02a7823c1c27b</td>\n",
       "      <td>67f274a673108b021563e4fb172371ea</td>\n",
       "      <td>cccabd230f51c6c97850f093cec4ee08</td>\n",
       "      <td>4.900900e+11</td>\n",
       "      <td>36.998209</td>\n",
       "      <td>-110.175732</td>\n",
       "      <td>Monument Vly</td>\n",
       "      <td>UT</td>\n",
       "      <td>rural</td>\n",
       "      <td>San Juan School District</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>163.68</td>\n",
       "      <td>14.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/6/13</td>\n",
       "      <td>12/19/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124948</th>\n",
       "      <td>fff0ce1935052d50a4485bd480db03a6</td>\n",
       "      <td>1533c37c1d202411324cdd2274777580</td>\n",
       "      <td>5af7cc9cc60ec8d4e62c4516f1abf0d5</td>\n",
       "      <td>6.334800e+10</td>\n",
       "      <td>35.349696</td>\n",
       "      <td>-119.162331</td>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>CA</td>\n",
       "      <td>rural</td>\n",
       "      <td>Rosedale Union School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Books</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1005.74</td>\n",
       "      <td>65.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/27/12</td>\n",
       "      <td>12/10/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124949</th>\n",
       "      <td>fff17ba5f8954c060395735b111edb96</td>\n",
       "      <td>490d0b530daeed042a70a2acc2be1dc7</td>\n",
       "      <td>06c41c32c946457e8545b81dca1ce5c8</td>\n",
       "      <td>3.701920e+11</td>\n",
       "      <td>36.047957</td>\n",
       "      <td>-79.989043</td>\n",
       "      <td>High Point</td>\n",
       "      <td>NC</td>\n",
       "      <td>urban</td>\n",
       "      <td>Guilford Co School District</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>223.61</td>\n",
       "      <td>14.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/15/12</td>\n",
       "      <td>12/21/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124950</th>\n",
       "      <td>fff1cbf1b7b26568ba57bb92992048b9</td>\n",
       "      <td>77c16c5f82bc583d9b13a3404f2daa37</td>\n",
       "      <td>8b819d840292b4c406ef7145b67b522d</td>\n",
       "      <td>3.600120e+11</td>\n",
       "      <td>40.681308</td>\n",
       "      <td>-73.856928</td>\n",
       "      <td>Ozone Park</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>Special Needs</td>\n",
       "      <td>Special Needs</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>786.40</td>\n",
       "      <td>24.0</td>\n",
       "      <td>f</td>\n",
       "      <td>9/25/12</td>\n",
       "      <td>12/27/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124951</th>\n",
       "      <td>fff213f5fb0e61d1ea9df3f992d54d6c</td>\n",
       "      <td>b69405d095b441c64c8d41dbbbab83c1</td>\n",
       "      <td>f9c1fe53a81895aa5064308bb537a592</td>\n",
       "      <td>3.701920e+11</td>\n",
       "      <td>36.048576</td>\n",
       "      <td>-79.778015</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>NC</td>\n",
       "      <td>urban</td>\n",
       "      <td>Guilford Co School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>701.95</td>\n",
       "      <td>22.0</td>\n",
       "      <td>t</td>\n",
       "      <td>8/11/13</td>\n",
       "      <td>10/26/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124952</th>\n",
       "      <td>fff24308118daa069f765ad2662234a6</td>\n",
       "      <td>855f5bbf58e3fcf59583777027329c6a</td>\n",
       "      <td>3579c9e1a2da2f06c6dd81877cda7054</td>\n",
       "      <td>2.731800e+11</td>\n",
       "      <td>44.036049</td>\n",
       "      <td>-92.484854</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>MN</td>\n",
       "      <td>urban</td>\n",
       "      <td>Rochester School District 535</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>490.66</td>\n",
       "      <td>25.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6/9/13</td>\n",
       "      <td>10/1/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124953</th>\n",
       "      <td>fff2880da80e1b5443c838599d92e95d</td>\n",
       "      <td>ce2367ccff54254c79a79bf09bcf32ed</td>\n",
       "      <td>fe61be541ea0878c1f718cd936da3aca</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.660793</td>\n",
       "      <td>-73.988731</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>ESL</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>395.40</td>\n",
       "      <td>120.0</td>\n",
       "      <td>t</td>\n",
       "      <td>9/14/13</td>\n",
       "      <td>10/25/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124954</th>\n",
       "      <td>fff2f8b3170013ecf9ee7304c7b0d6d7</td>\n",
       "      <td>d728647826402b266ae8dc0d40914ebd</td>\n",
       "      <td>f3315fbcad5794f7ae6c4f848e488c8c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.059349</td>\n",
       "      <td>-82.968307</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>OH</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ohio Department of Education</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>178.41</td>\n",
       "      <td>20.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/14/12</td>\n",
       "      <td>11/20/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124955</th>\n",
       "      <td>fff309b22dacd7a37db9cb9ccee1e031</td>\n",
       "      <td>15969f9fd415e45316f5df1e4f6f7114</td>\n",
       "      <td>b25832137d33953fdfbd74616cf1dc94</td>\n",
       "      <td>3.702970e+11</td>\n",
       "      <td>35.107920</td>\n",
       "      <td>-80.886379</td>\n",
       "      <td>Pineville</td>\n",
       "      <td>NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charlotte-mecklenburg Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>292.01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>9/5/12</td>\n",
       "      <td>10/12/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124956</th>\n",
       "      <td>fff3183fb122c03321ce10b81fda2f55</td>\n",
       "      <td>afdfef895e4033893531858b3b7b93e4</td>\n",
       "      <td>413160e89bb3924066db49f015d12e6a</td>\n",
       "      <td>1.812810e+11</td>\n",
       "      <td>39.770969</td>\n",
       "      <td>-86.276016</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>urban</td>\n",
       "      <td>Msd Of Wayne Twp</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>289.45</td>\n",
       "      <td>700.0</td>\n",
       "      <td>t</td>\n",
       "      <td>10/14/12</td>\n",
       "      <td>11/20/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124957</th>\n",
       "      <td>fff427a481a6ae0da7c79ee3a568a25d</td>\n",
       "      <td>2f4d0c10a6c3b90c1cdf700c1d1e8783</td>\n",
       "      <td>c7ee71e78a89b4537735625abe3df9e2</td>\n",
       "      <td>6.227101e+10</td>\n",
       "      <td>34.039135</td>\n",
       "      <td>-118.211122</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>859.99</td>\n",
       "      <td>60.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1/28/12</td>\n",
       "      <td>3/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124958</th>\n",
       "      <td>fff43d73c89c9c0fa3455f71f36846af</td>\n",
       "      <td>c3892f47501ebe7560bb47f044cb6c1a</td>\n",
       "      <td>ab38fb6eeb133c593bca3bd17060dfff</td>\n",
       "      <td>6.227101e+10</td>\n",
       "      <td>34.029933</td>\n",
       "      <td>-118.435195</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>560.99</td>\n",
       "      <td>120.0</td>\n",
       "      <td>t</td>\n",
       "      <td>10/2/12</td>\n",
       "      <td>10/25/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124959</th>\n",
       "      <td>fff4a452b872e91d3953849c26d66762</td>\n",
       "      <td>157dec98e29ea71d21c757c3b5d7807f</td>\n",
       "      <td>67a1d71fa445acf637993c210f67a464</td>\n",
       "      <td>1.303870e+11</td>\n",
       "      <td>32.487823</td>\n",
       "      <td>-84.979007</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>GA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Muscogee Co School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Other</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>518.05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>t</td>\n",
       "      <td>5/30/12</td>\n",
       "      <td>6/22/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124960</th>\n",
       "      <td>fff50452c8b57fabd715d5547997d659</td>\n",
       "      <td>a3b0edce360c46d821f3f949c37e0760</td>\n",
       "      <td>47266028aed99d00ce97ee299c89f0bb</td>\n",
       "      <td>6.227101e+10</td>\n",
       "      <td>34.200943</td>\n",
       "      <td>-118.530552</td>\n",
       "      <td>Reseda</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>757.47</td>\n",
       "      <td>40.0</td>\n",
       "      <td>t</td>\n",
       "      <td>8/28/12</td>\n",
       "      <td>9/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124961</th>\n",
       "      <td>fff5d11155a3d8e8c56a41fb2e79912c</td>\n",
       "      <td>442cff1ac9ba42e5dfcbbe3d924f4c07</td>\n",
       "      <td>f2e2d501f9ee2a961d1485e02019d148</td>\n",
       "      <td>5.509600e+11</td>\n",
       "      <td>43.125865</td>\n",
       "      <td>-87.955918</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>urban</td>\n",
       "      <td>Milwaukee Public Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>191.18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>t</td>\n",
       "      <td>8/12/12</td>\n",
       "      <td>9/6/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124962</th>\n",
       "      <td>fff5fd6f1a382a7a9ceff838f35212e1</td>\n",
       "      <td>987a7ad70c7f28fb06e969a3a3bfbb08</td>\n",
       "      <td>fa17c1ab6a40fcabbf1514163ae1c910</td>\n",
       "      <td>6.280501e+10</td>\n",
       "      <td>37.742393</td>\n",
       "      <td>-122.168290</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Oakland Unified School Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>208.46</td>\n",
       "      <td>22.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/3/12</td>\n",
       "      <td>4/13/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124963</th>\n",
       "      <td>fff8e52c5aac56e34c4d4eb5aa443c5d</td>\n",
       "      <td>9ed92b421feff227841dbe235da3a09c</td>\n",
       "      <td>77c73843c1a82cead04006069163dded</td>\n",
       "      <td>5.005310e+11</td>\n",
       "      <td>44.545620</td>\n",
       "      <td>-71.984150</td>\n",
       "      <td>Lyndonville</td>\n",
       "      <td>VT</td>\n",
       "      <td>rural</td>\n",
       "      <td>Caledonia North Su 8</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>386.46</td>\n",
       "      <td>27.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/12/12</td>\n",
       "      <td>1/1/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124964</th>\n",
       "      <td>fff8ea691f0be0e4ed486690eb56c14f</td>\n",
       "      <td>c530d7baec513b17570c7ea40df638e9</td>\n",
       "      <td>2dc015358468c294b523cf18aeac6669</td>\n",
       "      <td>2.926160e+11</td>\n",
       "      <td>36.729577</td>\n",
       "      <td>-93.385154</td>\n",
       "      <td>Reeds Spring</td>\n",
       "      <td>MO</td>\n",
       "      <td>rural</td>\n",
       "      <td>Reeds Spring School Dist R4</td>\n",
       "      <td>...</td>\n",
       "      <td>Early Development</td>\n",
       "      <td>Applied Learning</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>409.87</td>\n",
       "      <td>7.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/28/13</td>\n",
       "      <td>6/14/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124965</th>\n",
       "      <td>fffa75021cdd838e658b331847c78ad2</td>\n",
       "      <td>bd202f86ad86ba83875f754e7ff89964</td>\n",
       "      <td>6b1ea7aa5d39c00b9a260f60d9a35e86</td>\n",
       "      <td>1.602100e+11</td>\n",
       "      <td>43.648253</td>\n",
       "      <td>-116.347880</td>\n",
       "      <td>Boise</td>\n",
       "      <td>ID</td>\n",
       "      <td>urban</td>\n",
       "      <td>Meridian Joint School Dist 2</td>\n",
       "      <td>...</td>\n",
       "      <td>Early Development</td>\n",
       "      <td>Applied Learning</td>\n",
       "      <td>Technology</td>\n",
       "      <td>moderate poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1923.87</td>\n",
       "      <td>20.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/10/13</td>\n",
       "      <td>12/22/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124966</th>\n",
       "      <td>fffb88aa251449f1ba0b31d5552426b0</td>\n",
       "      <td>68a125f470e30903664d0e70e406d2b7</td>\n",
       "      <td>12629360afe5266b7e171f3cf57af5ec</td>\n",
       "      <td>6.344101e+10</td>\n",
       "      <td>37.725403</td>\n",
       "      <td>-122.430496</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>San Francisco Unified Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1018.24</td>\n",
       "      <td>510.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2/17/12</td>\n",
       "      <td>4/12/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124967</th>\n",
       "      <td>fffbc23d5c2ece64168af350ab9f6cad</td>\n",
       "      <td>4f23071c37c4aa0a96ea4ff336138c61</td>\n",
       "      <td>df83213f7800d05086a121ab1730b545</td>\n",
       "      <td>6.306601e+10</td>\n",
       "      <td>33.885330</td>\n",
       "      <td>-117.761117</td>\n",
       "      <td>Yorba Linda</td>\n",
       "      <td>CA</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Placentia Yorba Linda Usd</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>low poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>1003.81</td>\n",
       "      <td>738.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/13/13</td>\n",
       "      <td>1/16/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124968</th>\n",
       "      <td>fffc3632fd681fde1113eae31ca027d4</td>\n",
       "      <td>f52c695357488ae6e499cae04eb28802</td>\n",
       "      <td>3bca24ea3f5077ad0d0b86d979b3a6cf</td>\n",
       "      <td>4.807710e+11</td>\n",
       "      <td>29.909552</td>\n",
       "      <td>-95.360931</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Aldine Ind School District</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>331.56</td>\n",
       "      <td>24.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/31/12</td>\n",
       "      <td>1/5/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124969</th>\n",
       "      <td>fffc5f77d0ba9fb9b9510582caa30bdd</td>\n",
       "      <td>2580b6b605b2d3667cfce00b87ce47f9</td>\n",
       "      <td>3870254e36f88935745384ebc06a4caf</td>\n",
       "      <td>1.300120e+11</td>\n",
       "      <td>33.752884</td>\n",
       "      <td>-84.342140</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Atlanta Public Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>798.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/25/13</td>\n",
       "      <td>4/7/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124970</th>\n",
       "      <td>fffcab52aff6aec5843afafe919d4a06</td>\n",
       "      <td>64ec2ab31709511cce9d4b344eed4ef0</td>\n",
       "      <td>ce225b42cd7d04da6fc8d47815dce5fc</td>\n",
       "      <td>5.100270e+11</td>\n",
       "      <td>38.838849</td>\n",
       "      <td>-77.097328</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>VA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Arlington Public Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>717.96</td>\n",
       "      <td>24.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2/10/13</td>\n",
       "      <td>6/10/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124971</th>\n",
       "      <td>fffcfa4388e8ac482c44734bffa891c8</td>\n",
       "      <td>18b4c1437decf26b5f2c92b071962f82</td>\n",
       "      <td>212357c91e4f9db903e37691b80f1e46</td>\n",
       "      <td>3.600150e+11</td>\n",
       "      <td>40.615929</td>\n",
       "      <td>-73.912835</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>Character Education</td>\n",
       "      <td>Applied Learning</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>990.99</td>\n",
       "      <td>32.0</td>\n",
       "      <td>t</td>\n",
       "      <td>6/24/12</td>\n",
       "      <td>7/30/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124972</th>\n",
       "      <td>fffda9a35e156656df0a2e2c7091e9cf</td>\n",
       "      <td>9cc41ef1d42c253bde0866d2c490a6db</td>\n",
       "      <td>4e3fa7096549dae8b2c92cadd536b5f8</td>\n",
       "      <td>4.823640e+11</td>\n",
       "      <td>29.821455</td>\n",
       "      <td>-95.399082</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>urban</td>\n",
       "      <td>Houston Ind School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 9-12</td>\n",
       "      <td>873.32</td>\n",
       "      <td>156.0</td>\n",
       "      <td>t</td>\n",
       "      <td>10/20/13</td>\n",
       "      <td>12/15/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124973</th>\n",
       "      <td>fffe0bb8af3b9cd93046b49653cc923a</td>\n",
       "      <td>820b80005bdffb74fe85e4deb11c5a07</td>\n",
       "      <td>bb477994115ad6275e95623e927c040e</td>\n",
       "      <td>3.416290e+11</td>\n",
       "      <td>40.231834</td>\n",
       "      <td>-74.777481</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>urban</td>\n",
       "      <td>Trenton School District</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>184.05</td>\n",
       "      <td>20.0</td>\n",
       "      <td>f</td>\n",
       "      <td>9/2/12</td>\n",
       "      <td>10/17/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124974</th>\n",
       "      <td>fffe45b28ea6f2889de1e3f797fb31a3</td>\n",
       "      <td>defe5366f82c80715343e58cf95bd2ac</td>\n",
       "      <td>10a9c48f27d12ef702f27547db13a19b</td>\n",
       "      <td>8.069000e+10</td>\n",
       "      <td>39.875904</td>\n",
       "      <td>-105.031563</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>CO</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Adams 12 Five Star Schools</td>\n",
       "      <td>...</td>\n",
       "      <td>Performing Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Other</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>345.84</td>\n",
       "      <td>500.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/14/12</td>\n",
       "      <td>1/29/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124975</th>\n",
       "      <td>fffeebf4827d745aa36b17c2d38d1966</td>\n",
       "      <td>96c1a33b4f2b832595c3c6a01bc24c05</td>\n",
       "      <td>7bb6b1924a7bd181ab5568b062260966</td>\n",
       "      <td>6.346201e+10</td>\n",
       "      <td>38.654224</td>\n",
       "      <td>-121.308122</td>\n",
       "      <td>Fair Oaks</td>\n",
       "      <td>CA</td>\n",
       "      <td>suburban</td>\n",
       "      <td>San Juan Unified School Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>938.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>f</td>\n",
       "      <td>12/1/12</td>\n",
       "      <td>1/17/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124976 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               projectid                    teacher_acctid  \\\n",
       "0       00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1       0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2       000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3       0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4       0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "5       00049ec8ca1f2d08cb13cab31b0b85ec  7149611553c700de9a6099f8a9ce598b   \n",
       "6       0004d2fdbb571237fa53a97e7691440b  926671e209fb977bd5123145c1848ad1   \n",
       "7       0004ee26667e751dd51384eb9f30c72e  abe4dabb7864f4c548d230cf9070e03f   \n",
       "8       0006a31d45f8d52d217e7c5b55c11f37  3b5fada1ad0e339acc669829071320c4   \n",
       "9       0008ac907bf237a15a959244205d3ee5  92527a5ac5fe946ed1961fb2e1de8cc5   \n",
       "10      0009bc936fed4728d5fd86d92ee3cec1  66b77e507a30a5fbbcb4f7631c5ccc75   \n",
       "11      000a6dcbb21ec643daf74ed28991d29c  93e0a37fca3cd7c9c32a535673c48af4   \n",
       "12      000a981e6bd61c489bbebc237f7b6a0d  a886a532c21f83b0c30571208636dc0e   \n",
       "13      000b238b8c85214d58683b13398fd058  439f1e081199a89540cbf69866cfd182   \n",
       "14      000b574223b4f491c7de7bccae88b51d  5003eacb7e6311d01177c275c633768a   \n",
       "15      000bab2056ba84931f4f5bc72f542e03  10d2de84406c94967bb0f01f57ba980f   \n",
       "16      000be0b57987d6c29d650a88eac2961b  ae7b6b599922817b2e0cb9f96354297e   \n",
       "17      000d3ead6b648ba31043bb6376e6342d  3dd9af5310c77541f5b65cf190cec338   \n",
       "18      000e6a13fd69bf0e426403b1d5da0e99  1ad348085983de6a0f1fe6a37779f7f2   \n",
       "19      000e964b1e5c911adf700736c43e8f85  27076f8d0ec597bfd5035ef84d6691b0   \n",
       "20      000faa31e276e9e649360949207fa00c  86403b5f04ed07201cd04184ff4c0ced   \n",
       "21      0010040593d5e9699ee45834369ec817  1871e44279646e8d18fa74d29dcfc456   \n",
       "22      00103b0614e31016e5c4cc7d405bbc51  9e4433fb2d3078bc4dcbe2860d05ebf5   \n",
       "23      00105edf14ebb7f146d6ba2098639bb1  ac1ef23232ddd1597f6fa5b28a171fa5   \n",
       "24      001096473792e89ccc83e9f6ab01871b  e21c4208e61018ed35aa2bcc392a2d40   \n",
       "25      00134d14226ef613134712c54211f754  5bce35e3991721b665d33095e9d3aa31   \n",
       "26      00136585c0e4a67afaa964403cf9f45b  402cfc6b73dc62f44946bc1c381f6b1c   \n",
       "27      0013a402fb4cf84e3d60d7a59566dff8  511ec2a1372cd7b9e1af86b1b3de8bff   \n",
       "28      001468d419e1ee737f364013334d0c84  ca8d614f79013690baf1a8860be4b754   \n",
       "29      0014cedcb2d697902c15081ab12deadf  b9e31d1b986c0cf802c9e13869b86cef   \n",
       "...                                  ...                               ...   \n",
       "124946  fff008ba1051b272f9e5218b1c125169  4999b5d89891ff2279c63e8f529f00ea   \n",
       "124947  fff025ce2682430f72e02a7823c1c27b  67f274a673108b021563e4fb172371ea   \n",
       "124948  fff0ce1935052d50a4485bd480db03a6  1533c37c1d202411324cdd2274777580   \n",
       "124949  fff17ba5f8954c060395735b111edb96  490d0b530daeed042a70a2acc2be1dc7   \n",
       "124950  fff1cbf1b7b26568ba57bb92992048b9  77c16c5f82bc583d9b13a3404f2daa37   \n",
       "124951  fff213f5fb0e61d1ea9df3f992d54d6c  b69405d095b441c64c8d41dbbbab83c1   \n",
       "124952  fff24308118daa069f765ad2662234a6  855f5bbf58e3fcf59583777027329c6a   \n",
       "124953  fff2880da80e1b5443c838599d92e95d  ce2367ccff54254c79a79bf09bcf32ed   \n",
       "124954  fff2f8b3170013ecf9ee7304c7b0d6d7  d728647826402b266ae8dc0d40914ebd   \n",
       "124955  fff309b22dacd7a37db9cb9ccee1e031  15969f9fd415e45316f5df1e4f6f7114   \n",
       "124956  fff3183fb122c03321ce10b81fda2f55  afdfef895e4033893531858b3b7b93e4   \n",
       "124957  fff427a481a6ae0da7c79ee3a568a25d  2f4d0c10a6c3b90c1cdf700c1d1e8783   \n",
       "124958  fff43d73c89c9c0fa3455f71f36846af  c3892f47501ebe7560bb47f044cb6c1a   \n",
       "124959  fff4a452b872e91d3953849c26d66762  157dec98e29ea71d21c757c3b5d7807f   \n",
       "124960  fff50452c8b57fabd715d5547997d659  a3b0edce360c46d821f3f949c37e0760   \n",
       "124961  fff5d11155a3d8e8c56a41fb2e79912c  442cff1ac9ba42e5dfcbbe3d924f4c07   \n",
       "124962  fff5fd6f1a382a7a9ceff838f35212e1  987a7ad70c7f28fb06e969a3a3bfbb08   \n",
       "124963  fff8e52c5aac56e34c4d4eb5aa443c5d  9ed92b421feff227841dbe235da3a09c   \n",
       "124964  fff8ea691f0be0e4ed486690eb56c14f  c530d7baec513b17570c7ea40df638e9   \n",
       "124965  fffa75021cdd838e658b331847c78ad2  bd202f86ad86ba83875f754e7ff89964   \n",
       "124966  fffb88aa251449f1ba0b31d5552426b0  68a125f470e30903664d0e70e406d2b7   \n",
       "124967  fffbc23d5c2ece64168af350ab9f6cad  4f23071c37c4aa0a96ea4ff336138c61   \n",
       "124968  fffc3632fd681fde1113eae31ca027d4  f52c695357488ae6e499cae04eb28802   \n",
       "124969  fffc5f77d0ba9fb9b9510582caa30bdd  2580b6b605b2d3667cfce00b87ce47f9   \n",
       "124970  fffcab52aff6aec5843afafe919d4a06  64ec2ab31709511cce9d4b344eed4ef0   \n",
       "124971  fffcfa4388e8ac482c44734bffa891c8  18b4c1437decf26b5f2c92b071962f82   \n",
       "124972  fffda9a35e156656df0a2e2c7091e9cf  9cc41ef1d42c253bde0866d2c490a6db   \n",
       "124973  fffe0bb8af3b9cd93046b49653cc923a  820b80005bdffb74fe85e4deb11c5a07   \n",
       "124974  fffe45b28ea6f2889de1e3f797fb31a3  defe5366f82c80715343e58cf95bd2ac   \n",
       "124975  fffeebf4827d745aa36b17c2d38d1966  96c1a33b4f2b832595c3c6a01bc24c05   \n",
       "\n",
       "                                schoolid  school_ncesid  school_latitude  \\\n",
       "0       9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1       3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2       dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3       8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4       fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "5       462a5fd93cf9fb5d41eecfd2ea860b19   2.621150e+11        42.740157   \n",
       "6       1a994778027ab086dc58ec3b47f74ff0   4.047200e+10        33.059361   \n",
       "7       8409f70bcd81bc06e4b9efca68eed8f6   6.280501e+10        37.761958   \n",
       "8       c6a033f9349ea70659c1891b119680ed   2.307320e+11        44.096641   \n",
       "9       23e34f5d2e2940684269cffe35741598   6.271800e+10        34.381832   \n",
       "10      af67655269d03992889a8db7fe0cf83d   6.072000e+10        37.263773   \n",
       "11      7e28905e0126e37d9b747e92c5fcf44d   2.926850e+11        38.535275   \n",
       "12      c995de8108ac314637e1c869f81af766   1.709930e+11        41.922711   \n",
       "13      685d2471561270abe3820d947fbbe3e9   6.225000e+10        33.773256   \n",
       "14      87e515cc802d93213adfb963ef8de30e   3.600090e+11        40.813916   \n",
       "15      d0318b91338cd9dd6f18202eebe7c9c2            NaN        30.013238   \n",
       "16      922a11f9ab72afebccf5b9391191e1bd   2.102490e+11        37.803213   \n",
       "17      8018b1c81de3aede5363afabcf32b17c   4.088000e+10        32.228378   \n",
       "18      82571bc4db2e4cd846e3c50eeceeb176   6.227100e+10        34.182137   \n",
       "19      3870254e36f88935745384ebc06a4caf   1.300120e+11        33.752884   \n",
       "20      c86d87fee34b13377658337fa8bf2fc5   2.931440e+11        38.367966   \n",
       "21      83b74057d63f2da28f3635efeffd61a1   1.707650e+11        40.456921   \n",
       "22      b22babfd8fbdfa6b53e4747b74da02dd   4.835850e+11        33.183766   \n",
       "23      33b6121da948b2fd67fd78f5935eb793   6.261900e+10        34.050485   \n",
       "24      7fdffcfd5bea8e0fc99952254a875a72   1.200870e+11        28.155807   \n",
       "25      9b62c64683b7c3212f159e13eb41ff5c   1.812720e+11        39.920792   \n",
       "26      0793efaeba83d8b5b9d55f5772fac62d            NaN        35.906952   \n",
       "27      dbde53d7dbafbbb22ca60f36bb0019a5   6.227101e+10        34.227558   \n",
       "28      4157e4e610804d738f2d1a450d36dd3f   1.200180e+11        26.240857   \n",
       "29      1d74e61c912fe4527eb57ac456bcac8a   3.600090e+11        40.837411   \n",
       "...                                  ...            ...              ...   \n",
       "124946  8803e5495d05529e09083007ac95f58b   4.808090e+11        29.434906   \n",
       "124947  cccabd230f51c6c97850f093cec4ee08   4.900900e+11        36.998209   \n",
       "124948  5af7cc9cc60ec8d4e62c4516f1abf0d5   6.334800e+10        35.349696   \n",
       "124949  06c41c32c946457e8545b81dca1ce5c8   3.701920e+11        36.047957   \n",
       "124950  8b819d840292b4c406ef7145b67b522d   3.600120e+11        40.681308   \n",
       "124951  f9c1fe53a81895aa5064308bb537a592   3.701920e+11        36.048576   \n",
       "124952  3579c9e1a2da2f06c6dd81877cda7054   2.731800e+11        44.036049   \n",
       "124953  fe61be541ea0878c1f718cd936da3aca   3.600090e+11        40.660793   \n",
       "124954  f3315fbcad5794f7ae6c4f848e488c8c            NaN        40.059349   \n",
       "124955  b25832137d33953fdfbd74616cf1dc94   3.702970e+11        35.107920   \n",
       "124956  413160e89bb3924066db49f015d12e6a   1.812810e+11        39.770969   \n",
       "124957  c7ee71e78a89b4537735625abe3df9e2   6.227101e+10        34.039135   \n",
       "124958  ab38fb6eeb133c593bca3bd17060dfff   6.227101e+10        34.029933   \n",
       "124959  67a1d71fa445acf637993c210f67a464   1.303870e+11        32.487823   \n",
       "124960  47266028aed99d00ce97ee299c89f0bb   6.227101e+10        34.200943   \n",
       "124961  f2e2d501f9ee2a961d1485e02019d148   5.509600e+11        43.125865   \n",
       "124962  fa17c1ab6a40fcabbf1514163ae1c910   6.280501e+10        37.742393   \n",
       "124963  77c73843c1a82cead04006069163dded   5.005310e+11        44.545620   \n",
       "124964  2dc015358468c294b523cf18aeac6669   2.926160e+11        36.729577   \n",
       "124965  6b1ea7aa5d39c00b9a260f60d9a35e86   1.602100e+11        43.648253   \n",
       "124966  12629360afe5266b7e171f3cf57af5ec   6.344101e+10        37.725403   \n",
       "124967  df83213f7800d05086a121ab1730b545   6.306601e+10        33.885330   \n",
       "124968  3bca24ea3f5077ad0d0b86d979b3a6cf   4.807710e+11        29.909552   \n",
       "124969  3870254e36f88935745384ebc06a4caf   1.300120e+11        33.752884   \n",
       "124970  ce225b42cd7d04da6fc8d47815dce5fc   5.100270e+11        38.838849   \n",
       "124971  212357c91e4f9db903e37691b80f1e46   3.600150e+11        40.615929   \n",
       "124972  4e3fa7096549dae8b2c92cadd536b5f8   4.823640e+11        29.821455   \n",
       "124973  bb477994115ad6275e95623e927c040e   3.416290e+11        40.231834   \n",
       "124974  10a9c48f27d12ef702f27547db13a19b   8.069000e+10        39.875904   \n",
       "124975  7bb6b1924a7bd181ab5568b062260966   6.346201e+10        38.654224   \n",
       "\n",
       "        school_longitude    school_city school_state school_metro  \\\n",
       "0             -87.673257        Chicago           IL        urban   \n",
       "1            -119.296596        Ventura           CA        urban   \n",
       "2            -118.257834    Los Angeles           CA        urban   \n",
       "3             -73.988217       Brooklyn           NY        urban   \n",
       "4             -73.205635  Central Islip           NY     suburban   \n",
       "5             -84.525821        Lansing           MI        urban   \n",
       "6            -112.037727       Maricopa           AZ        rural   \n",
       "7            -122.193209        Oakland           CA        urban   \n",
       "8             -70.191734       Lewiston           ME        urban   \n",
       "9            -118.531837        Newhall           CA     suburban   \n",
       "10           -121.996427       Saratoga           CA     suburban   \n",
       "11            -90.464493         Fenton           MO     suburban   \n",
       "12            -87.692965        Chicago           IL        urban   \n",
       "13           -118.183848     Long Beach           CA        urban   \n",
       "14            -73.900522          Bronx           NY        urban   \n",
       "15            -81.391606   St Augustine           FL     suburban   \n",
       "16            -85.987333     Vine Grove           KY     suburban   \n",
       "17           -110.963287         Tucson           AZ        urban   \n",
       "18           -118.424728       Van Nuys           CA        urban   \n",
       "19            -84.342140        Atlanta           GA        urban   \n",
       "20            -92.477882  Ft Leonard Wd           MO          NaN   \n",
       "21            -88.137198         Paxton           IL          NaN   \n",
       "22            -96.494366      Princeton           TX          NaN   \n",
       "23           -118.020442       El Monte           CA     suburban   \n",
       "24            -82.532195           Lutz           FL     suburban   \n",
       "25            -86.142952   Indianapolis           IN        urban   \n",
       "26            -77.540756        Tarboro           NC        rural   \n",
       "27           -118.499130    North Hills           CA        urban   \n",
       "28            -80.165433  Pompano Beach           FL        urban   \n",
       "29            -73.854644          Bronx           NY        urban   \n",
       "...                  ...            ...          ...          ...   \n",
       "124946        -95.254405          Alvin           TX     suburban   \n",
       "124947       -110.175732   Monument Vly           UT        rural   \n",
       "124948       -119.162331    Bakersfield           CA        rural   \n",
       "124949        -79.989043     High Point           NC        urban   \n",
       "124950        -73.856928     Ozone Park           NY        urban   \n",
       "124951        -79.778015     Greensboro           NC        urban   \n",
       "124952        -92.484854      Rochester           MN        urban   \n",
       "124953        -73.988731       Brooklyn           NY        urban   \n",
       "124954        -82.968307       Columbus           OH        urban   \n",
       "124955        -80.886379      Pineville           NC          NaN   \n",
       "124956        -86.276016   Indianapolis           IN        urban   \n",
       "124957       -118.211122    Los Angeles           CA        urban   \n",
       "124958       -118.435195    Los Angeles           CA        urban   \n",
       "124959        -84.979007       Columbus           GA        urban   \n",
       "124960       -118.530552         Reseda           CA        urban   \n",
       "124961        -87.955918      Milwaukee           WI        urban   \n",
       "124962       -122.168290        Oakland           CA        urban   \n",
       "124963        -71.984150    Lyndonville           VT        rural   \n",
       "124964        -93.385154   Reeds Spring           MO        rural   \n",
       "124965       -116.347880          Boise           ID        urban   \n",
       "124966       -122.430496  San Francisco           CA        urban   \n",
       "124967       -117.761117    Yorba Linda           CA     suburban   \n",
       "124968        -95.360931        Houston           TX     suburban   \n",
       "124969        -84.342140        Atlanta           GA        urban   \n",
       "124970        -77.097328      Arlington           VA        urban   \n",
       "124971        -73.912835       Brooklyn           NY        urban   \n",
       "124972        -95.399082        Houston           TX        urban   \n",
       "124973        -74.777481        Trenton           NJ        urban   \n",
       "124974       -105.031563    Westminster           CO     suburban   \n",
       "124975       -121.308122      Fair Oaks           CA     suburban   \n",
       "\n",
       "                                  school_district  ...  \\\n",
       "0                           Pershing Elem Network  ...   \n",
       "1                    Ventura Unif School District  ...   \n",
       "2                       Los Angeles Unif Sch Dist  ...   \n",
       "3                        New York City Dept Of Ed  ...   \n",
       "4                     Central Islip Union Free SD  ...   \n",
       "5                         Lansing School District  ...   \n",
       "6                   Maricopa Unif Sch District 20  ...   \n",
       "7                     Oakland Unified School Dist  ...   \n",
       "8                         Lewiston Public Schools  ...   \n",
       "9                         Newhall School District  ...   \n",
       "10                 Campbell Union School District  ...   \n",
       "11                    Rockwood School District R6  ...   \n",
       "12                         Fullerton Elem Network  ...   \n",
       "13                 Long Beach Unified School Dist  ...   \n",
       "14                       New York City Dept Of Ed  ...   \n",
       "15                    St Johns Co School District  ...   \n",
       "16                      Hardin Co School District  ...   \n",
       "17                     Tucson Unified School Dist  ...   \n",
       "18                      Los Angeles Unif Sch Dist  ...   \n",
       "19                         Atlanta Public Schools  ...   \n",
       "20                     Waynesville School Dist R6  ...   \n",
       "21                    Paxton-buckley-loda Cusd 10  ...   \n",
       "22                      Princeton Ind School Dist  ...   \n",
       "23      Mountain View School District-Los Angeles  ...   \n",
       "24                   Hillsborough Co Pub Sch Dist  ...   \n",
       "25                   Washington Township Sch Dist  ...   \n",
       "26                      North Carolina Dept of Ed  ...   \n",
       "27                      Los Angeles Unif Sch Dist  ...   \n",
       "28                      Broward Co Public Schools  ...   \n",
       "29                       New York City Dept Of Ed  ...   \n",
       "...                                           ...  ...   \n",
       "124946                  Alvin Ind School District  ...   \n",
       "124947                   San Juan School District  ...   \n",
       "124948             Rosedale Union School District  ...   \n",
       "124949                Guilford Co School District  ...   \n",
       "124950                   New York City Dept Of Ed  ...   \n",
       "124951                Guilford Co School District  ...   \n",
       "124952              Rochester School District 535  ...   \n",
       "124953                   New York City Dept Of Ed  ...   \n",
       "124954               Ohio Department of Education  ...   \n",
       "124955             Charlotte-mecklenburg Sch Dist  ...   \n",
       "124956                           Msd Of Wayne Twp  ...   \n",
       "124957                  Los Angeles Unif Sch Dist  ...   \n",
       "124958                  Los Angeles Unif Sch Dist  ...   \n",
       "124959                Muscogee Co School District  ...   \n",
       "124960                  Los Angeles Unif Sch Dist  ...   \n",
       "124961                   Milwaukee Public Schools  ...   \n",
       "124962                Oakland Unified School Dist  ...   \n",
       "124963                       Caledonia North Su 8  ...   \n",
       "124964                Reeds Spring School Dist R4  ...   \n",
       "124965               Meridian Joint School Dist 2  ...   \n",
       "124966             San Francisco Unified Sch Dist  ...   \n",
       "124967                  Placentia Yorba Linda Usd  ...   \n",
       "124968                 Aldine Ind School District  ...   \n",
       "124969                     Atlanta Public Schools  ...   \n",
       "124970                   Arlington Public Schools  ...   \n",
       "124971                   New York City Dept Of Ed  ...   \n",
       "124972                Houston Ind School District  ...   \n",
       "124973                    Trenton School District  ...   \n",
       "124974                 Adams 12 Five Star Schools  ...   \n",
       "124975               San Juan Unified School Dist  ...   \n",
       "\n",
       "       secondary_focus_subject secondary_focus_area resource_type  \\\n",
       "0                  Visual Arts     Music & The Arts      Supplies   \n",
       "1         Literature & Writing  Literacy & Language         Books   \n",
       "2              Social Sciences     History & Civics    Technology   \n",
       "3                          NaN                  NaN         Books   \n",
       "4         Literature & Writing  Literacy & Language    Technology   \n",
       "5                          NaN                  NaN         Other   \n",
       "6                          NaN                  NaN      Supplies   \n",
       "7                          NaN                  NaN         Books   \n",
       "8                          NaN                  NaN    Technology   \n",
       "9                     Literacy  Literacy & Language    Technology   \n",
       "10                    Literacy  Literacy & Language         Other   \n",
       "11                         NaN                  NaN         Other   \n",
       "12                         NaN                  NaN      Supplies   \n",
       "13               Gym & Fitness      Health & Sports      Supplies   \n",
       "14                         NaN                  NaN         Books   \n",
       "15        Literature & Writing  Literacy & Language         Books   \n",
       "16       Health & Life Science       Math & Science      Supplies   \n",
       "17                         NaN                  NaN         Other   \n",
       "18                         NaN                  NaN         Books   \n",
       "19                 Mathematics       Math & Science      Supplies   \n",
       "20                         NaN                  NaN    Technology   \n",
       "21                         NaN                  NaN      Supplies   \n",
       "22                         NaN                  NaN      Supplies   \n",
       "23               Special Needs        Special Needs    Technology   \n",
       "24                         NaN                  NaN    Technology   \n",
       "25                         NaN                  NaN         Books   \n",
       "26                         NaN                  NaN         Books   \n",
       "27                         NaN                  NaN    Technology   \n",
       "28               Special Needs        Special Needs      Supplies   \n",
       "29           Early Development     Applied Learning    Technology   \n",
       "...                        ...                  ...           ...   \n",
       "124946                     NaN                  NaN         Books   \n",
       "124947                     NaN                  NaN    Technology   \n",
       "124948             Visual Arts     Music & The Arts         Books   \n",
       "124949                     NaN                  NaN      Supplies   \n",
       "124950           Special Needs        Special Needs    Technology   \n",
       "124951    Literature & Writing  Literacy & Language    Technology   \n",
       "124952    Literature & Writing  Literacy & Language      Supplies   \n",
       "124953                     ESL  Literacy & Language         Books   \n",
       "124954                     NaN                  NaN      Supplies   \n",
       "124955                     NaN                  NaN      Supplies   \n",
       "124956                     NaN                  NaN      Supplies   \n",
       "124957                     NaN                  NaN         Books   \n",
       "124958                     NaN                  NaN    Technology   \n",
       "124959                Literacy  Literacy & Language         Other   \n",
       "124960                     NaN                  NaN    Technology   \n",
       "124961                     NaN                  NaN      Supplies   \n",
       "124962                Literacy  Literacy & Language         Books   \n",
       "124963    Literature & Writing  Literacy & Language         Books   \n",
       "124964       Early Development     Applied Learning      Supplies   \n",
       "124965       Early Development     Applied Learning    Technology   \n",
       "124966                     NaN                  NaN      Supplies   \n",
       "124967                     NaN                  NaN    Technology   \n",
       "124968                     NaN                  NaN         Books   \n",
       "124969                Literacy  Literacy & Language    Technology   \n",
       "124970                     NaN                  NaN         Books   \n",
       "124971     Character Education     Applied Learning      Supplies   \n",
       "124972             Visual Arts     Music & The Arts    Technology   \n",
       "124973                     NaN                  NaN         Books   \n",
       "124974         Performing Arts     Music & The Arts         Other   \n",
       "124975                     NaN                  NaN         Other   \n",
       "\n",
       "           poverty_level    grade_level  \\\n",
       "0        highest poverty  Grades PreK-2   \n",
       "1        highest poverty     Grades 3-5   \n",
       "2           high poverty     Grades 3-5   \n",
       "3           high poverty  Grades PreK-2   \n",
       "4           high poverty  Grades PreK-2   \n",
       "5        highest poverty     Grades 3-5   \n",
       "6           high poverty     Grades 3-5   \n",
       "7        highest poverty    Grades 9-12   \n",
       "8           high poverty     Grades 3-5   \n",
       "9        highest poverty  Grades PreK-2   \n",
       "10           low poverty     Grades 3-5   \n",
       "11      moderate poverty     Grades 3-5   \n",
       "12       highest poverty  Grades PreK-2   \n",
       "13       highest poverty  Grades PreK-2   \n",
       "14       highest poverty  Grades PreK-2   \n",
       "15      moderate poverty  Grades PreK-2   \n",
       "16          high poverty     Grades 6-8   \n",
       "17          high poverty  Grades PreK-2   \n",
       "18       highest poverty     Grades 3-5   \n",
       "19       highest poverty     Grades 3-5   \n",
       "20          high poverty     Grades 3-5   \n",
       "21      moderate poverty    Grades 9-12   \n",
       "22       highest poverty     Grades 3-5   \n",
       "23       highest poverty  Grades PreK-2   \n",
       "24           low poverty  Grades PreK-2   \n",
       "25       highest poverty  Grades PreK-2   \n",
       "26          high poverty     Grades 6-8   \n",
       "27       highest poverty     Grades 3-5   \n",
       "28       highest poverty     Grades 3-5   \n",
       "29       highest poverty  Grades PreK-2   \n",
       "...                  ...            ...   \n",
       "124946   highest poverty  Grades PreK-2   \n",
       "124947   highest poverty  Grades PreK-2   \n",
       "124948  moderate poverty     Grades 3-5   \n",
       "124949  moderate poverty     Grades 6-8   \n",
       "124950   highest poverty     Grades 3-5   \n",
       "124951   highest poverty     Grades 3-5   \n",
       "124952  moderate poverty    Grades 9-12   \n",
       "124953   highest poverty     Grades 6-8   \n",
       "124954      high poverty  Grades PreK-2   \n",
       "124955   highest poverty  Grades PreK-2   \n",
       "124956   highest poverty     Grades 3-5   \n",
       "124957   highest poverty    Grades 9-12   \n",
       "124958   highest poverty    Grades 9-12   \n",
       "124959   highest poverty    Grades 9-12   \n",
       "124960   highest poverty    Grades 9-12   \n",
       "124961   highest poverty  Grades PreK-2   \n",
       "124962   highest poverty  Grades PreK-2   \n",
       "124963      high poverty     Grades 3-5   \n",
       "124964      high poverty  Grades PreK-2   \n",
       "124965  moderate poverty  Grades PreK-2   \n",
       "124966   highest poverty     Grades 3-5   \n",
       "124967       low poverty     Grades 6-8   \n",
       "124968   highest poverty  Grades PreK-2   \n",
       "124969   highest poverty     Grades 3-5   \n",
       "124970      high poverty  Grades PreK-2   \n",
       "124971      high poverty     Grades 3-5   \n",
       "124972      high poverty    Grades 9-12   \n",
       "124973   highest poverty     Grades 3-5   \n",
       "124974   highest poverty     Grades 3-5   \n",
       "124975   highest poverty     Grades 6-8   \n",
       "\n",
       "       total_price_including_optional_support students_reached  \\\n",
       "0                                     1498.61             31.0   \n",
       "1                                      282.47             28.0   \n",
       "2                                     1012.38             56.0   \n",
       "3                                      175.33             23.0   \n",
       "4                                     3591.11            150.0   \n",
       "5                                      475.85             15.0   \n",
       "6                                      390.65             37.0   \n",
       "7                                     3877.20             30.0   \n",
       "8                                      838.75             25.0   \n",
       "9                                     1477.44             24.0   \n",
       "10                                     194.11             25.0   \n",
       "11                                     714.22             25.0   \n",
       "12                                     523.27            700.0   \n",
       "13                                    1108.94            809.0   \n",
       "14                                     677.73             24.0   \n",
       "15                                     165.75             18.0   \n",
       "16                                     481.18            120.0   \n",
       "17                                     265.13             53.0   \n",
       "18                                     296.68             30.0   \n",
       "19                                    1098.39             39.0   \n",
       "20                                     632.13             25.0   \n",
       "21                                     221.56            100.0   \n",
       "22                                    1125.40            660.0   \n",
       "23                                    2130.40             30.0   \n",
       "24                                     715.67             17.0   \n",
       "25                                     518.22             27.0   \n",
       "26                                     350.69             50.0   \n",
       "27                                     836.34             29.0   \n",
       "28                                     281.95             60.0   \n",
       "29                                     371.81             30.0   \n",
       "...                                       ...              ...   \n",
       "124946                                 957.15             40.0   \n",
       "124947                                 163.68             14.0   \n",
       "124948                                1005.74             65.0   \n",
       "124949                                 223.61             14.0   \n",
       "124950                                 786.40             24.0   \n",
       "124951                                 701.95             22.0   \n",
       "124952                                 490.66             25.0   \n",
       "124953                                 395.40            120.0   \n",
       "124954                                 178.41             20.0   \n",
       "124955                                 292.01             19.0   \n",
       "124956                                 289.45            700.0   \n",
       "124957                                 859.99             60.0   \n",
       "124958                                 560.99            120.0   \n",
       "124959                                 518.05             63.0   \n",
       "124960                                 757.47             40.0   \n",
       "124961                                 191.18             18.0   \n",
       "124962                                 208.46             22.0   \n",
       "124963                                 386.46             27.0   \n",
       "124964                                 409.87              7.0   \n",
       "124965                                1923.87             20.0   \n",
       "124966                                1018.24            510.0   \n",
       "124967                                1003.81            738.0   \n",
       "124968                                 331.56             24.0   \n",
       "124969                                 798.26             20.0   \n",
       "124970                                 717.96             24.0   \n",
       "124971                                 990.99             32.0   \n",
       "124972                                 873.32            156.0   \n",
       "124973                                 184.05             20.0   \n",
       "124974                                 345.84            500.0   \n",
       "124975                                 938.00             11.0   \n",
       "\n",
       "       eligible_double_your_impact_match date_posted datefullyfunded  \n",
       "0                                      f     4/14/13          5/2/13  \n",
       "1                                      t      4/7/12         4/18/12  \n",
       "2                                      f     1/30/12         4/15/12  \n",
       "3                                      f    10/11/12         12/5/12  \n",
       "4                                      f      1/8/13         3/25/13  \n",
       "5                                      f    11/30/12         2/26/13  \n",
       "6                                      f     3/26/13         4/17/13  \n",
       "7                                      f     2/28/13         3/10/13  \n",
       "8                                      f     8/21/13         9/13/13  \n",
       "9                                      f     10/3/12         11/3/12  \n",
       "10                                     f     7/29/13        11/26/13  \n",
       "11                                     f     6/22/13        10/17/13  \n",
       "12                                     f     1/22/13         2/28/13  \n",
       "13                                     f    10/27/13        11/29/13  \n",
       "14                                     t     5/28/13          9/6/13  \n",
       "15                                     f     12/9/12         1/22/13  \n",
       "16                                     f     1/26/12         5/17/12  \n",
       "17                                     f     1/15/13         3/11/13  \n",
       "18                                     t     1/23/12         2/20/12  \n",
       "19                                     f    12/22/12         1/12/13  \n",
       "20                                     f    12/18/12          1/6/13  \n",
       "21                                     t      9/4/13        10/27/13  \n",
       "22                                     f    12/10/13          4/2/14  \n",
       "23                                     f     4/29/12         7/16/12  \n",
       "24                                     f    11/19/13        12/19/13  \n",
       "25                                     f     3/31/12         7/27/12  \n",
       "26                                     f     5/30/12          8/5/12  \n",
       "27                                     f     1/21/12          3/1/12  \n",
       "28                                     f      8/7/12         9/19/12  \n",
       "29                                     f     9/22/13         12/5/13  \n",
       "...                                  ...         ...             ...  \n",
       "124946                                 f     12/9/12        12/22/12  \n",
       "124947                                 f     12/6/13        12/19/13  \n",
       "124948                                 f    10/27/12        12/10/12  \n",
       "124949                                 f    10/15/12        12/21/12  \n",
       "124950                                 f     9/25/12        12/27/12  \n",
       "124951                                 t     8/11/13        10/26/13  \n",
       "124952                                 f      6/9/13         10/1/13  \n",
       "124953                                 t     9/14/13        10/25/13  \n",
       "124954                                 f    10/14/12        11/20/12  \n",
       "124955                                 f      9/5/12        10/12/12  \n",
       "124956                                 t    10/14/12        11/20/12  \n",
       "124957                                 t     1/28/12          3/5/12  \n",
       "124958                                 t     10/2/12        10/25/12  \n",
       "124959                                 t     5/30/12         6/22/12  \n",
       "124960                                 t     8/28/12          9/5/12  \n",
       "124961                                 t     8/12/12          9/6/12  \n",
       "124962                                 t      4/3/12         4/13/12  \n",
       "124963                                 f    12/12/12          1/1/13  \n",
       "124964                                 f     4/28/13         6/14/13  \n",
       "124965                                 f    12/10/13        12/22/13  \n",
       "124966                                 f     2/17/12         4/12/12  \n",
       "124967                                 f    10/13/13         1/16/14  \n",
       "124968                                 f    10/31/12          1/5/13  \n",
       "124969                                 f    12/25/13          4/7/14  \n",
       "124970                                 f     2/10/13         6/10/13  \n",
       "124971                                 t     6/24/12         7/30/12  \n",
       "124972                                 t    10/20/13        12/15/13  \n",
       "124973                                 f      9/2/12        10/17/12  \n",
       "124974                                 f     1/14/12         1/29/12  \n",
       "124975                                 f     12/1/12         1/17/13  \n",
       "\n",
       "[124976 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline.read('data/projects_2012_2013.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataframe\n",
    "\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projectid                                  object\n",
      "teacher_acctid                             object\n",
      "schoolid                                   object\n",
      "school_ncesid                             float64\n",
      "school_latitude                           float64\n",
      "school_longitude                          float64\n",
      "school_city                                object\n",
      "school_state                               object\n",
      "school_metro                               object\n",
      "school_district                            object\n",
      "school_county                              object\n",
      "school_charter                             object\n",
      "school_magnet                              object\n",
      "teacher_prefix                             object\n",
      "primary_focus_subject                      object\n",
      "primary_focus_area                         object\n",
      "secondary_focus_subject                    object\n",
      "secondary_focus_area                       object\n",
      "resource_type                              object\n",
      "poverty_level                              object\n",
      "grade_level                                object\n",
      "total_price_including_optional_support    float64\n",
      "students_reached                          float64\n",
      "eligible_double_your_impact_match          object\n",
      "date_posted                                object\n",
      "datefullyfunded                            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pipeline.columns_types(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our data is discrete, with a few exceptions.\n",
    "\n",
    "* Number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124976\n"
     ]
    }
   ],
   "source": [
    "pipeline.count_obs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is long enough for generating supervised learning models.\n",
    "\n",
    "* Counting duplicates for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pipeline.duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, no duplicated observations.\n",
    "\n",
    "* Counting duplicates -- project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pipeline.duplicates_in_columns(df, ['projectid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates in project ID.\n",
    "\n",
    "* Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projectid has 0.0 % of missing data points\n",
      "teacher_acctid has 0.0 % of missing data points\n",
      "schoolid has 0.0 % of missing data points\n",
      "school_ncesid has 7.38781846114454 % of missing data points\n",
      "school_latitude has 0.0 % of missing data points\n",
      "school_longitude has 0.0 % of missing data points\n",
      "school_city has 0.0 % of missing data points\n",
      "school_state has 0.0 % of missing data points\n",
      "school_metro has 12.181538855460248 % of missing data points\n",
      "school_district has 0.1376264242734605 % of missing data points\n",
      "school_county has 0.0 % of missing data points\n",
      "school_charter has 0.0 % of missing data points\n",
      "school_magnet has 0.0 % of missing data points\n",
      "teacher_prefix has 0.0 % of missing data points\n",
      "primary_focus_subject has 0.012002304442452951 % of missing data points\n",
      "primary_focus_area has 0.012002304442452951 % of missing data points\n",
      "secondary_focus_subject has 32.45103059787479 % of missing data points\n",
      "secondary_focus_area has 32.45103059787479 % of missing data points\n",
      "resource_type has 0.013602611701446677 % of missing data points\n",
      "poverty_level has 0.0 % of missing data points\n",
      "grade_level has 0.0024004608884905902 % of missing data points\n",
      "total_price_including_optional_support has 0.0 % of missing data points\n",
      "students_reached has 0.047209064140314935 % of missing data points\n",
      "eligible_double_your_impact_match has 0.0 % of missing data points\n",
      "date_posted has 0.0 % of missing data points\n",
      "datefullyfunded has 0.0 % of missing data points\n"
     ]
    }
   ],
   "source": [
    "pipeline.count_missings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values in some of the variables we could use as features. Here is how we'll treat them:\n",
    "\n",
    "1. We'll leave out of the analysis the variable `school_ncesid`. It is a school ID and we won't need it to train/test our algorithm.\n",
    "2. We'll also leave out `school_metro` and `school_district`. Being discrete school administration/location variables, their information is probable very correlated with other variables, such as `school_city` and `school_county`.\n",
    "3. We'll assume that the missings in `primary_focus_subject`, `primary_focus_area`, `secondary_focus_subject`,  `secondary_focus_area`, `resource_type` and `grade_level` are actually conveying some information. Thus, we'll impute the label 'None' in these missing values.\n",
    "4. Finally, in `students_reached` we'll impute the median. Notice that this variable in continuous.\n",
    "\n",
    "Also, it's important to note that the variables we'll use to generate our label and the train/test splits don't have missing values (`date_posted`, `datefullyfunded`).\n",
    "\n",
    "* Checking some basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                               124976\n",
      "unique                              124976\n",
      "top       6e68a5151f21995ef8042ce4478a71c1\n",
      "freq                                     1\n",
      "Name: projectid, dtype: object\n",
      "count                               124976\n",
      "unique                               77013\n",
      "top       214acf23d183dfa2f1dc16e7b3658320\n",
      "freq                                    63\n",
      "Name: teacher_acctid, dtype: object\n",
      "count                               124976\n",
      "unique                               29947\n",
      "top       10179fd362d7b8cf0e89baa1ca3025bb\n",
      "freq                                   193\n",
      "Name: schoolid, dtype: object\n",
      "count    1.157430e+05\n",
      "mean     2.448448e+11\n",
      "std      1.644728e+11\n",
      "min      1.000050e+10\n",
      "25%      6.344101e+10\n",
      "50%      2.200870e+11\n",
      "75%      3.704880e+11\n",
      "max      6.100010e+11\n",
      "Name: school_ncesid, dtype: float64\n",
      "count    124976.000000\n",
      "mean         36.827284\n",
      "std           4.963669\n",
      "min          18.249140\n",
      "25%          33.872504\n",
      "50%          36.617410\n",
      "75%          40.676156\n",
      "max          65.672562\n",
      "Name: school_latitude, dtype: float64\n",
      "count    124976.000000\n",
      "mean        -95.859299\n",
      "std          18.392876\n",
      "min        -171.690554\n",
      "25%        -117.806418\n",
      "50%         -90.101563\n",
      "75%         -80.713740\n",
      "max         -66.628036\n",
      "Name: school_longitude, dtype: float64\n",
      "count          124976\n",
      "unique           5955\n",
      "top       Los Angeles\n",
      "freq             5747\n",
      "Name: school_city, dtype: object\n",
      "count     124976\n",
      "unique        51\n",
      "top           CA\n",
      "freq       29227\n",
      "Name: school_state, dtype: object\n",
      "count     109752\n",
      "unique         3\n",
      "top        urban\n",
      "freq       62267\n",
      "Name: school_metro, dtype: object\n",
      "count                        124804\n",
      "unique                         5970\n",
      "top       Los Angeles Unif Sch Dist\n",
      "freq                          10867\n",
      "Name: school_district, dtype: object\n",
      "count          124976\n",
      "unique           1470\n",
      "top       Los Angeles\n",
      "freq            13037\n",
      "Name: school_county, dtype: object\n",
      "count     124976\n",
      "unique         2\n",
      "top            f\n",
      "freq      113340\n",
      "Name: school_charter, dtype: object\n",
      "count     124976\n",
      "unique         2\n",
      "top            f\n",
      "freq      114273\n",
      "Name: school_magnet, dtype: object\n",
      "count     124976\n",
      "unique         4\n",
      "top         Mrs.\n",
      "freq       60190\n",
      "Name: teacher_prefix, dtype: object\n",
      "count       124961\n",
      "unique          27\n",
      "top       Literacy\n",
      "freq         37408\n",
      "Name: primary_focus_subject, dtype: object\n",
      "count                  124961\n",
      "unique                      7\n",
      "top       Literacy & Language\n",
      "freq                    56051\n",
      "Name: primary_focus_area, dtype: object\n",
      "count        84420\n",
      "unique          27\n",
      "top       Literacy\n",
      "freq         12598\n",
      "Name: secondary_focus_subject, dtype: object\n",
      "count                   84420\n",
      "unique                      7\n",
      "top       Literacy & Language\n",
      "freq                    30056\n",
      "Name: secondary_focus_area, dtype: object\n",
      "count         124959\n",
      "unique             6\n",
      "top       Technology\n",
      "freq           45886\n",
      "Name: resource_type, dtype: object\n",
      "count              124976\n",
      "unique                  4\n",
      "top       highest poverty\n",
      "freq                67752\n",
      "Name: poverty_level, dtype: object\n",
      "count            124973\n",
      "unique                4\n",
      "top       Grades PreK-2\n",
      "freq              47730\n",
      "Name: grade_level, dtype: object\n",
      "count    124976.000000\n",
      "mean        654.011811\n",
      "std        1098.015854\n",
      "min          92.000000\n",
      "25%         345.810000\n",
      "50%         510.500000\n",
      "75%         752.960000\n",
      "max      164382.840000\n",
      "Name: total_price_including_optional_support, dtype: float64\n",
      "count    124917.000000\n",
      "mean         95.445760\n",
      "std         163.481912\n",
      "min           1.000000\n",
      "25%          23.000000\n",
      "50%          30.000000\n",
      "75%         100.000000\n",
      "max       12143.000000\n",
      "Name: students_reached, dtype: float64\n",
      "count     124976\n",
      "unique         2\n",
      "top            f\n",
      "freq       87887\n",
      "Name: eligible_double_your_impact_match, dtype: object\n",
      "count      124976\n",
      "unique        731\n",
      "top       9/30/12\n",
      "freq          728\n",
      "Name: date_posted, dtype: object\n",
      "count       124976\n",
      "unique         845\n",
      "top       10/25/13\n",
      "freq           341\n",
      "Name: datefullyfunded, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pipeline.describe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the following, for our subsequent data preparation:\n",
    "\n",
    "Identifier variables:\n",
    "\n",
    "* `project_id`\n",
    "* `teacher_acctid`\n",
    "* `schoolid`\n",
    "* `school_ncesid`\n",
    "\n",
    "Discrete variables:\n",
    " \n",
    "* `school_magnet`\n",
    "* `school_charter`\n",
    "* `eligible_double_your_impact_match`\n",
    " \n",
    "Categorical variables:\n",
    " \n",
    "* `school_city`\n",
    "* `school_state`\n",
    "* `school_metro`\n",
    "* `school_district`\n",
    "* `school_county`\n",
    "* `school_charter`\n",
    "* `teacher_prefix`\n",
    "* `primary_focus_subject`\n",
    "* `primary_focus_area`\n",
    "* `secondary_focus_subject`\n",
    "* `secondary_focus_area`\n",
    "* `resource_type`\n",
    "* `poverty_level`\n",
    "* `grade_level`\n",
    "\n",
    "Continuous variables:\n",
    " \n",
    "* `school_latitude`\n",
    "* `school_longitude`\n",
    "* `total_price_including_optional_support`\n",
    "* `students_reached`\n",
    "\n",
    "Date variables:\n",
    "\n",
    "* `date_posted`\n",
    "* `datefullyfunded`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataframes\n",
    "\n",
    "Here's what we'll do:\n",
    "\n",
    "1. Transform date features into date types\n",
    "2. Add dummies for each value of every categorical variable\n",
    "3. Generate the label attribute\n",
    "4. Generate the train/test sets\n",
    "5. Discretize categorical variables and impute missing values in each train/test set\n",
    "6. Define the columns we'll use as features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "1. Transforming date features into date types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_vars = ['date_posted', 'datefullyfunded']\n",
    "for col in date_vars:\n",
    "    pipeline.to_date(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Adding dummies for each value of every categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Replacing missing values with the label 'None':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_label_cols = ['primary_focus_subject', 'primary_focus_area', 'secondary_focus_subject', 'secondary_focus_area', \\\n",
    "                   'resource_type', 'grade_level']\n",
    "for col in none_label_cols:\n",
    "    pipeline.fill_nas_other(df, col, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we generate the dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['school_state', 'school_metro', 'teacher_prefix', 'primary_focus_area', \\\n",
    "               'secondary_focus_area', 'resource_type', 'poverty_level', 'grade_level']\n",
    "for col in categorical:\n",
    "    pipeline.create_dummies(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generating the label attribute -- notice that we want to predict if a project will not get funding within the first 60 days of having being posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>2012-04-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-12-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>2013-04-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>2013-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>2013-09-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>2012-11-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>2013-11-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>2013-09-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>2012-05-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>2013-03-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012-01-23</td>\n",
       "      <td>2012-02-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012-12-22</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-09-04</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012-04-29</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-11-19</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>2012-08-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012-01-21</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012-08-07</td>\n",
       "      <td>2012-09-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-09-22</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124946</th>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>2012-12-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124947</th>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124948</th>\n",
       "      <td>2012-10-27</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124949</th>\n",
       "      <td>2012-10-15</td>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124950</th>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124951</th>\n",
       "      <td>2013-08-11</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124952</th>\n",
       "      <td>2013-06-09</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124953</th>\n",
       "      <td>2013-09-14</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124954</th>\n",
       "      <td>2012-10-14</td>\n",
       "      <td>2012-11-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124955</th>\n",
       "      <td>2012-09-05</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124956</th>\n",
       "      <td>2012-10-14</td>\n",
       "      <td>2012-11-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124957</th>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>2012-03-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124958</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124959</th>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>2012-06-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124960</th>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>2012-09-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124961</th>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124962</th>\n",
       "      <td>2012-04-03</td>\n",
       "      <td>2012-04-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124963</th>\n",
       "      <td>2012-12-12</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124964</th>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124965</th>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124966</th>\n",
       "      <td>2012-02-17</td>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124967</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>2014-01-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124968</th>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124969</th>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124970</th>\n",
       "      <td>2013-02-10</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124971</th>\n",
       "      <td>2012-06-24</td>\n",
       "      <td>2012-07-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124972</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124973</th>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>2012-10-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124974</th>\n",
       "      <td>2012-01-14</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124975</th>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>2013-01-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124976 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_posted datefullyfunded  label\n",
       "0       2013-04-14      2013-05-02      0\n",
       "1       2012-04-07      2012-04-18      0\n",
       "2       2012-01-30      2012-04-15      1\n",
       "3       2012-10-11      2012-12-05      0\n",
       "4       2013-01-08      2013-03-25      1\n",
       "5       2012-11-30      2013-02-26      1\n",
       "6       2013-03-26      2013-04-17      0\n",
       "7       2013-02-28      2013-03-10      0\n",
       "8       2013-08-21      2013-09-13      0\n",
       "9       2012-10-03      2012-11-03      0\n",
       "10      2013-07-29      2013-11-26      1\n",
       "11      2013-06-22      2013-10-17      1\n",
       "12      2013-01-22      2013-02-28      0\n",
       "13      2013-10-27      2013-11-29      0\n",
       "14      2013-05-28      2013-09-06      1\n",
       "15      2012-12-09      2013-01-22      0\n",
       "16      2012-01-26      2012-05-17      1\n",
       "17      2013-01-15      2013-03-11      0\n",
       "18      2012-01-23      2012-02-20      0\n",
       "19      2012-12-22      2013-01-12      0\n",
       "20      2012-12-18      2013-01-06      0\n",
       "21      2013-09-04      2013-10-27      0\n",
       "22      2013-12-10      2014-04-02      1\n",
       "23      2012-04-29      2012-07-16      1\n",
       "24      2013-11-19      2013-12-19      0\n",
       "25      2012-03-31      2012-07-27      1\n",
       "26      2012-05-30      2012-08-05      1\n",
       "27      2012-01-21      2012-03-01      0\n",
       "28      2012-08-07      2012-09-19      0\n",
       "29      2013-09-22      2013-12-05      1\n",
       "...            ...             ...    ...\n",
       "124946  2012-12-09      2012-12-22      0\n",
       "124947  2013-12-06      2013-12-19      0\n",
       "124948  2012-10-27      2012-12-10      0\n",
       "124949  2012-10-15      2012-12-21      1\n",
       "124950  2012-09-25      2012-12-27      1\n",
       "124951  2013-08-11      2013-10-26      1\n",
       "124952  2013-06-09      2013-10-01      1\n",
       "124953  2013-09-14      2013-10-25      0\n",
       "124954  2012-10-14      2012-11-20      0\n",
       "124955  2012-09-05      2012-10-12      0\n",
       "124956  2012-10-14      2012-11-20      0\n",
       "124957  2012-01-28      2012-03-05      0\n",
       "124958  2012-10-02      2012-10-25      0\n",
       "124959  2012-05-30      2012-06-22      0\n",
       "124960  2012-08-28      2012-09-05      0\n",
       "124961  2012-08-12      2012-09-06      0\n",
       "124962  2012-04-03      2012-04-13      0\n",
       "124963  2012-12-12      2013-01-01      0\n",
       "124964  2013-04-28      2013-06-14      0\n",
       "124965  2013-12-10      2013-12-22      0\n",
       "124966  2012-02-17      2012-04-12      0\n",
       "124967  2013-10-13      2014-01-16      1\n",
       "124968  2012-10-31      2013-01-05      1\n",
       "124969  2013-12-25      2014-04-07      1\n",
       "124970  2013-02-10      2013-06-10      1\n",
       "124971  2012-06-24      2012-07-30      0\n",
       "124972  2013-10-20      2013-12-15      0\n",
       "124973  2012-09-02      2012-10-17      0\n",
       "124974  2012-01-14      2012-01-29      0\n",
       "124975  2012-12-01      2013-01-17      0\n",
       "\n",
       "[124976 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = 60\n",
    "pipeline.create_time_label(df, 'date_posted', 'datefullyfunded', days)\n",
    "df[date_vars + ['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generating the train/test sets. We also store them in a dictionary we'll use for generating the evaluation table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holdout 1\n",
      "train upper threshold: 2012-05-01 00:00:00\n",
      "Notice that we leave a gap of 60 days\n",
      "test lower threshold: 2012-06-30 00:00:00\n",
      "test upper threshold: 2012-12-30 00:00:00\n",
      "\n",
      "Holdout 2\n",
      "train upper threshold: 2012-11-01 00:00:00\n",
      "Notice that we leave a gap of 60 days\n",
      "test lower threshold: 2012-12-31 00:00:00\n",
      "test upper threshold: 2013-06-30 00:00:00\n",
      "\n",
      "Holdout 3\n",
      "train upper threshold: 2013-05-01 00:00:00\n",
      "Notice that we leave a gap of 60 days\n",
      "test lower threshold: 2013-06-30 00:00:00\n",
      "test upper threshold: 2013-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "months = 6\n",
    "time_feature = 'date_posted'\n",
    "threshold1 = '06/30/2012'\n",
    "threshold2 = '12/31/2012'\n",
    "threshold3 = '06/30/2013'\n",
    "\n",
    "print('\\nHoldout 1')\n",
    "df_train1, df_test1 = pipeline.time_based_split(df, time_feature, threshold1, days, months)\n",
    "print('\\nHoldout 2')\n",
    "df_train2, df_test2 = pipeline.time_based_split(df, time_feature, threshold2, days, months)\n",
    "print('\\nHoldout 3')\n",
    "df_train3, df_test3 = pipeline.time_based_split(df, time_feature, threshold3, days, months)\n",
    "\n",
    "sets = [df_train1, df_train2, df_train3, df_test1, df_test2, df_test3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Discretizing categorical variables and imputing missing values in each train/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Replacing missing values with the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cols = ['students_reached']\n",
    "for dataset in sets:\n",
    "    for col in median_cols:\n",
    "        pipeline.fill_nas_median(dataset, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transforming discrete variables into 0/1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_vars = ['school_magnet', 'school_charter', 'eligible_double_your_impact_match']\n",
    "for dataset in sets:\n",
    "    for col in discrete_vars:\n",
    "        pipeline.discrete_0_1(dataset, col, 'f', 't')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating dummies for each quartile of the continuous variables we'll use as features: (notice that we won't use `students_reached` as a feature because according to the [data dictionary](https://www.kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-choose/data) that variable is available after a project is funded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['total_price_including_optional_support']\n",
    "for dataset in sets:\n",
    "    for col in continuous:\n",
    "        pipeline.discretize(dataset, col)\n",
    "        pipeline.create_dummies(dataset, col + '_quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Defining the columns we'll use as features and our datasets dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['school_charter', 'school_magnet', 'eligible_double_your_impact_match', 'school_state_IL', \\\n",
    "            'school_state_CA', 'school_state_NY', 'school_state_MI', 'school_state_AZ', 'school_state_ME', \\\n",
    "            'school_state_MO', 'school_state_FL', 'school_state_KY', 'school_state_GA', 'school_state_TX', \\\n",
    "            'school_state_IN', 'school_state_NC', 'school_state_SC', 'school_state_CT', 'school_state_OH', \\\n",
    "            'school_state_MN', 'school_state_WV', 'school_state_WA', 'school_state_TN', 'school_state_OK', \\\n",
    "            'school_state_DC', 'school_state_MD', 'school_state_MS', 'school_state_ID', 'school_state_MA', \\\n",
    "            'school_state_IA', 'school_state_AK', 'school_state_WI', 'school_state_NV', 'school_state_LA', \\\n",
    "            'school_state_NE', 'school_state_CO', 'school_state_KS', 'school_state_OR', 'school_state_VA', \\\n",
    "            'school_state_PA', 'school_state_NJ', 'school_state_SD', 'school_state_MT', 'school_state_NH', \\\n",
    "            'school_state_AR', 'school_state_UT', 'school_state_WY', 'school_state_ND', 'school_state_HI', \\\n",
    "            'school_state_AL', 'school_state_RI', 'school_state_DE', 'school_state_NM', 'school_state_VT', \\\n",
    "            'school_metro_urban', 'school_metro_suburban', 'school_metro_rural', 'school_metro_nan', \\\n",
    "            'teacher_prefix_Mrs.', 'teacher_prefix_Ms.', 'teacher_prefix_Mr.', 'teacher_prefix_Dr.', \\\n",
    "            'primary_focus_area_Math & Science', 'primary_focus_area_History & Civics', \\\n",
    "            'primary_focus_area_Literacy & Language', 'primary_focus_area_Applied Learning', \\\n",
    "            'primary_focus_area_Music & The Arts', 'primary_focus_area_Health & Sports', \\\n",
    "            'primary_focus_area_Special Needs', 'primary_focus_area_None', 'secondary_focus_area_Music & The Arts', \\\n",
    "            'secondary_focus_area_Literacy & Language', 'secondary_focus_area_History & Civics', \\\n",
    "            'secondary_focus_area_None', 'secondary_focus_area_Health & Sports', \\\n",
    "            'secondary_focus_area_Math & Science', 'secondary_focus_area_Special Needs', \\\n",
    "            'secondary_focus_area_Applied Learning', 'resource_type_Supplies', 'resource_type_Books', \\\n",
    "            'resource_type_Technology', 'resource_type_Other', 'resource_type_Trips', 'resource_type_Visitors', \\\n",
    "            'resource_type_None', 'grade_level_None', 'poverty_level_highest poverty', 'poverty_level_high poverty', \\\n",
    "            'poverty_level_low poverty', 'poverty_level_moderate poverty', 'grade_level_Grades PreK-2', \\\n",
    "            'grade_level_Grades 3-5', 'grade_level_Grades 9-12', 'grade_level_Grades 6-8', \\\n",
    "            'total_price_including_optional_support_quartile_4.0', \\\n",
    "            'total_price_including_optional_support_quartile_1.0', \\\n",
    "            'total_price_including_optional_support_quartile_2.0', \\\n",
    "            'total_price_including_optional_support_quartile_3.0']\n",
    "label = 'label'\n",
    "datasets = {'Holdout 1: ' + threshold1: [df_train1, df_test1],\n",
    "            'Holdout 2: ' + threshold2: [df_train2, df_test2],\n",
    "            'Holdout 3: ' + threshold3: [df_train3, df_test3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the evaluation table\n",
    "\n",
    "We'll use two global variables in our pipeline script where we have defined a dictionary of classifiers and a dictionary of parameters we could use (`pipeline.CLASSIFIERS` and `pipeline.PARAMETERS`), but notice that the `evaluation_table` function can also be used with any dictionary of classifiers and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Holdout 2: 12/31/2012\n",
      "Predicting every data point's value to be 0, the accuracy is 68.5 %\n",
      "\n",
      "Running model 1 out of 324\n",
      "Progress: 0.3 %\n",
      "\n",
      "Running model 2 out of 324\n",
      "Progress: 0.6 %\n",
      "\n",
      "Running model 3 out of 324\n",
      "Progress: 0.9 %\n",
      "\n",
      "Running model 4 out of 324\n",
      "Progress: 1.2 %\n",
      "\n",
      "Running model 5 out of 324\n",
      "Progress: 1.5 %\n",
      "\n",
      "Running model 6 out of 324\n",
      "Progress: 1.9 %\n",
      "\n",
      "Running model 7 out of 324\n",
      "Progress: 2.2 %\n",
      "\n",
      "Running model 8 out of 324\n",
      "Progress: 2.5 %\n",
      "\n",
      "Running model 9 out of 324\n",
      "Progress: 2.8 %\n",
      "\n",
      "Running model 10 out of 324\n",
      "Progress: 3.1 %\n",
      "\n",
      "Running model 11 out of 324\n",
      "Progress: 3.4 %\n",
      "\n",
      "Running model 12 out of 324\n",
      "Progress: 3.7 %\n",
      "\n",
      "Running model 13 out of 324\n",
      "Progress: 4.0 %\n",
      "\n",
      "Running model 14 out of 324\n",
      "Progress: 4.3 %\n",
      "\n",
      "Running model 15 out of 324\n",
      "Progress: 4.6 %\n",
      "\n",
      "Running model 16 out of 324\n",
      "Progress: 4.9 %\n",
      "\n",
      "Running model 17 out of 324\n",
      "Progress: 5.2 %\n",
      "\n",
      "Running model 18 out of 324\n",
      "Progress: 5.6 %\n",
      "\n",
      "Running model 19 out of 324\n",
      "Progress: 5.9 %\n",
      "\n",
      "Running model 20 out of 324\n",
      "Progress: 6.2 %\n",
      "\n",
      "Running model 21 out of 324\n",
      "Progress: 6.5 %\n",
      "\n",
      "Running model 22 out of 324\n",
      "Progress: 6.8 %\n",
      "\n",
      "Running model 23 out of 324\n",
      "Progress: 7.1 %\n",
      "\n",
      "Running model 24 out of 324\n",
      "Progress: 7.4 %\n",
      "\n",
      "Running model 25 out of 324\n",
      "Progress: 7.7 %\n",
      "\n",
      "Running model 26 out of 324\n",
      "Progress: 8.0 %\n",
      "\n",
      "Running model 27 out of 324\n",
      "Progress: 8.3 %\n",
      "\n",
      "Running model 28 out of 324\n",
      "Progress: 8.6 %\n",
      "\n",
      "Running model 29 out of 324\n",
      "Progress: 9.0 %\n",
      "\n",
      "Running model 30 out of 324\n",
      "Progress: 9.3 %\n",
      "\n",
      "Running model 31 out of 324\n",
      "Progress: 9.6 %\n",
      "\n",
      "Running model 32 out of 324\n",
      "Progress: 9.9 %\n",
      "\n",
      "Running model 33 out of 324\n",
      "Progress: 10.2 %\n",
      "\n",
      "Running model 34 out of 324\n",
      "Progress: 10.5 %\n",
      "\n",
      "Running model 35 out of 324\n",
      "Progress: 10.8 %\n",
      "\n",
      "Running model 36 out of 324\n",
      "Progress: 11.1 %\n",
      "\n",
      "Running model 37 out of 324\n",
      "Progress: 11.4 %\n",
      "\n",
      "Running model 38 out of 324\n",
      "Progress: 11.7 %\n",
      "\n",
      "Running model 39 out of 324\n",
      "Progress: 12.0 %\n",
      "\n",
      "Running model 40 out of 324\n",
      "Progress: 12.3 %\n",
      "\n",
      "Running model 41 out of 324\n",
      "Progress: 12.7 %\n",
      "\n",
      "Running model 42 out of 324\n",
      "Progress: 13.0 %\n",
      "\n",
      "Running model 43 out of 324\n",
      "Progress: 13.3 %\n",
      "\n",
      "Running model 44 out of 324\n",
      "Progress: 13.6 %\n",
      "\n",
      "Running model 45 out of 324\n",
      "Progress: 13.9 %\n",
      "\n",
      "Running model 46 out of 324\n",
      "Progress: 14.2 %\n",
      "\n",
      "Running model 47 out of 324\n",
      "Progress: 14.5 %\n",
      "\n",
      "Running model 48 out of 324\n",
      "Progress: 14.8 %\n",
      "\n",
      "Running model 49 out of 324\n",
      "Progress: 15.1 %\n",
      "\n",
      "Running model 50 out of 324\n",
      "Progress: 15.4 %\n",
      "\n",
      "Running model 51 out of 324\n",
      "Progress: 15.7 %\n",
      "\n",
      "Running model 52 out of 324\n",
      "Progress: 16.0 %\n",
      "\n",
      "Running model 53 out of 324\n",
      "Progress: 16.4 %\n",
      "\n",
      "Running model 54 out of 324\n",
      "Progress: 16.7 %\n",
      "\n",
      "Running model 55 out of 324\n",
      "Progress: 17.0 %\n",
      "\n",
      "Running model 56 out of 324\n",
      "Progress: 17.3 %\n",
      "\n",
      "Running model 57 out of 324\n",
      "Progress: 17.6 %\n",
      "\n",
      "Running model 58 out of 324\n",
      "Progress: 17.9 %\n",
      "\n",
      "Running model 59 out of 324\n",
      "Progress: 18.2 %\n",
      "\n",
      "Running model 60 out of 324\n",
      "Progress: 18.5 %\n",
      "\n",
      "Running model 61 out of 324\n",
      "Progress: 18.8 %\n",
      "\n",
      "Running model 62 out of 324\n",
      "Progress: 19.1 %\n",
      "\n",
      "Running model 63 out of 324\n",
      "Progress: 19.4 %\n",
      "\n",
      "Running model 64 out of 324\n",
      "Progress: 19.8 %\n",
      "\n",
      "Running model 65 out of 324\n",
      "Progress: 20.1 %\n",
      "\n",
      "Running model 66 out of 324\n",
      "Progress: 20.4 %\n",
      "\n",
      "Running model 67 out of 324\n",
      "Progress: 20.7 %\n",
      "\n",
      "Running model 68 out of 324\n",
      "Progress: 21.0 %\n",
      "\n",
      "Running model 69 out of 324\n",
      "Progress: 21.3 %\n",
      "\n",
      "Running model 70 out of 324\n",
      "Progress: 21.6 %\n",
      "\n",
      "Running model 71 out of 324\n",
      "Progress: 21.9 %\n",
      "\n",
      "Running model 72 out of 324\n",
      "Progress: 22.2 %\n",
      "\n",
      "Running model 73 out of 324\n",
      "Progress: 22.5 %\n",
      "\n",
      "Running model 74 out of 324\n",
      "Progress: 22.8 %\n",
      "\n",
      "Running model 75 out of 324\n",
      "Progress: 23.1 %\n",
      "\n",
      "Running model 76 out of 324\n",
      "Progress: 23.5 %\n",
      "\n",
      "Running model 77 out of 324\n",
      "Progress: 23.8 %\n",
      "\n",
      "Running model 78 out of 324\n",
      "Progress: 24.1 %\n",
      "\n",
      "Running model 79 out of 324\n",
      "Progress: 24.4 %\n",
      "\n",
      "Running model 80 out of 324\n",
      "Progress: 24.7 %\n",
      "\n",
      "Running model 81 out of 324\n",
      "Progress: 25.0 %\n",
      "\n",
      "Running model 82 out of 324\n",
      "Progress: 25.3 %\n",
      "\n",
      "Running model 83 out of 324\n",
      "Progress: 25.6 %\n",
      "\n",
      "Running model 84 out of 324\n",
      "Progress: 25.9 %\n",
      "\n",
      "Running model 85 out of 324\n",
      "Progress: 26.2 %\n",
      "\n",
      "Running model 86 out of 324\n",
      "Progress: 26.5 %\n",
      "\n",
      "Running model 87 out of 324\n",
      "Progress: 26.9 %\n",
      "\n",
      "Running model 88 out of 324\n",
      "Progress: 27.2 %\n",
      "\n",
      "Running model 89 out of 324\n",
      "Progress: 27.5 %\n",
      "\n",
      "Running model 90 out of 324\n",
      "Progress: 27.8 %\n",
      "\n",
      "Running model 91 out of 324\n",
      "Progress: 28.1 %\n",
      "\n",
      "Running model 92 out of 324\n",
      "Progress: 28.4 %\n",
      "\n",
      "Running model 93 out of 324\n",
      "Progress: 28.7 %\n",
      "\n",
      "Running model 94 out of 324\n",
      "Progress: 29.0 %\n",
      "\n",
      "Running model 95 out of 324\n",
      "Progress: 29.3 %\n",
      "\n",
      "Running model 96 out of 324\n",
      "Progress: 29.6 %\n",
      "\n",
      "Running model 97 out of 324\n",
      "Progress: 29.9 %\n",
      "\n",
      "Running model 98 out of 324\n",
      "Progress: 30.2 %\n",
      "\n",
      "Running model 99 out of 324\n",
      "Progress: 30.6 %\n",
      "\n",
      "Running model 100 out of 324\n",
      "Progress: 30.9 %\n",
      "\n",
      "Running model 101 out of 324\n",
      "Progress: 31.2 %\n",
      "\n",
      "Running model 102 out of 324\n",
      "Progress: 31.5 %\n",
      "\n",
      "Running model 103 out of 324\n",
      "Progress: 31.8 %\n",
      "\n",
      "Running model 104 out of 324\n",
      "Progress: 32.1 %\n",
      "\n",
      "Running model 105 out of 324\n",
      "Progress: 32.4 %\n",
      "\n",
      "Running model 106 out of 324\n",
      "Progress: 32.7 %\n",
      "\n",
      "Running model 107 out of 324\n",
      "Progress: 33.0 %\n",
      "\n",
      "Running model 108 out of 324\n",
      "Progress: 33.3 %\n",
      "Dataset: Holdout 3: 06/30/2013\n",
      "Predicting every data point's value to be 0, the accuracy is 71.5 %\n",
      "\n",
      "Running model 109 out of 324\n",
      "Progress: 33.6 %\n",
      "\n",
      "Running model 110 out of 324\n",
      "Progress: 34.0 %\n",
      "\n",
      "Running model 111 out of 324\n",
      "Progress: 34.3 %\n",
      "\n",
      "Running model 112 out of 324\n",
      "Progress: 34.6 %\n",
      "\n",
      "Running model 113 out of 324\n",
      "Progress: 34.9 %\n",
      "\n",
      "Running model 114 out of 324\n",
      "Progress: 35.2 %\n",
      "\n",
      "Running model 115 out of 324\n",
      "Progress: 35.5 %\n",
      "\n",
      "Running model 116 out of 324\n",
      "Progress: 35.8 %\n",
      "\n",
      "Running model 117 out of 324\n",
      "Progress: 36.1 %\n",
      "\n",
      "Running model 118 out of 324\n",
      "Progress: 36.4 %\n",
      "\n",
      "Running model 119 out of 324\n",
      "Progress: 36.7 %\n",
      "\n",
      "Running model 120 out of 324\n",
      "Progress: 37.0 %\n",
      "\n",
      "Running model 121 out of 324\n",
      "Progress: 37.3 %\n",
      "\n",
      "Running model 122 out of 324\n",
      "Progress: 37.7 %\n",
      "\n",
      "Running model 123 out of 324\n",
      "Progress: 38.0 %\n",
      "\n",
      "Running model 124 out of 324\n",
      "Progress: 38.3 %\n",
      "\n",
      "Running model 125 out of 324\n",
      "Progress: 38.6 %\n",
      "\n",
      "Running model 126 out of 324\n",
      "Progress: 38.9 %\n",
      "\n",
      "Running model 127 out of 324\n",
      "Progress: 39.2 %\n",
      "\n",
      "Running model 128 out of 324\n",
      "Progress: 39.5 %\n",
      "\n",
      "Running model 129 out of 324\n",
      "Progress: 39.8 %\n",
      "\n",
      "Running model 130 out of 324\n",
      "Progress: 40.1 %\n",
      "\n",
      "Running model 131 out of 324\n",
      "Progress: 40.4 %\n",
      "\n",
      "Running model 132 out of 324\n",
      "Progress: 40.7 %\n",
      "\n",
      "Running model 133 out of 324\n",
      "Progress: 41.0 %\n",
      "\n",
      "Running model 134 out of 324\n",
      "Progress: 41.4 %\n",
      "\n",
      "Running model 135 out of 324\n",
      "Progress: 41.7 %\n",
      "\n",
      "Running model 136 out of 324\n",
      "Progress: 42.0 %\n",
      "\n",
      "Running model 137 out of 324\n",
      "Progress: 42.3 %\n",
      "\n",
      "Running model 138 out of 324\n",
      "Progress: 42.6 %\n",
      "\n",
      "Running model 139 out of 324\n",
      "Progress: 42.9 %\n",
      "\n",
      "Running model 140 out of 324\n",
      "Progress: 43.2 %\n",
      "\n",
      "Running model 141 out of 324\n",
      "Progress: 43.5 %\n",
      "\n",
      "Running model 142 out of 324\n",
      "Progress: 43.8 %\n",
      "\n",
      "Running model 143 out of 324\n",
      "Progress: 44.1 %\n",
      "\n",
      "Running model 144 out of 324\n",
      "Progress: 44.4 %\n",
      "\n",
      "Running model 145 out of 324\n",
      "Progress: 44.8 %\n",
      "\n",
      "Running model 146 out of 324\n",
      "Progress: 45.1 %\n",
      "\n",
      "Running model 147 out of 324\n",
      "Progress: 45.4 %\n",
      "\n",
      "Running model 148 out of 324\n",
      "Progress: 45.7 %\n",
      "\n",
      "Running model 149 out of 324\n",
      "Progress: 46.0 %\n",
      "\n",
      "Running model 150 out of 324\n",
      "Progress: 46.3 %\n",
      "\n",
      "Running model 151 out of 324\n",
      "Progress: 46.6 %\n",
      "\n",
      "Running model 152 out of 324\n",
      "Progress: 46.9 %\n",
      "\n",
      "Running model 153 out of 324\n",
      "Progress: 47.2 %\n",
      "\n",
      "Running model 154 out of 324\n",
      "Progress: 47.5 %\n",
      "\n",
      "Running model 155 out of 324\n",
      "Progress: 47.8 %\n",
      "\n",
      "Running model 156 out of 324\n",
      "Progress: 48.1 %\n",
      "\n",
      "Running model 157 out of 324\n",
      "Progress: 48.5 %\n",
      "\n",
      "Running model 158 out of 324\n",
      "Progress: 48.8 %\n",
      "\n",
      "Running model 159 out of 324\n",
      "Progress: 49.1 %\n",
      "\n",
      "Running model 160 out of 324\n",
      "Progress: 49.4 %\n",
      "\n",
      "Running model 161 out of 324\n",
      "Progress: 49.7 %\n",
      "\n",
      "Running model 162 out of 324\n",
      "Progress: 50.0 %\n",
      "\n",
      "Running model 163 out of 324\n",
      "Progress: 50.3 %\n",
      "\n",
      "Running model 164 out of 324\n",
      "Progress: 50.6 %\n",
      "\n",
      "Running model 165 out of 324\n",
      "Progress: 50.9 %\n",
      "\n",
      "Running model 166 out of 324\n",
      "Progress: 51.2 %\n",
      "\n",
      "Running model 167 out of 324\n",
      "Progress: 51.5 %\n",
      "\n",
      "Running model 168 out of 324\n",
      "Progress: 51.9 %\n",
      "\n",
      "Running model 169 out of 324\n",
      "Progress: 52.2 %\n",
      "\n",
      "Running model 170 out of 324\n",
      "Progress: 52.5 %\n",
      "\n",
      "Running model 171 out of 324\n",
      "Progress: 52.8 %\n",
      "\n",
      "Running model 172 out of 324\n",
      "Progress: 53.1 %\n",
      "\n",
      "Running model 173 out of 324\n",
      "Progress: 53.4 %\n",
      "\n",
      "Running model 174 out of 324\n",
      "Progress: 53.7 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model 175 out of 324\n",
      "Progress: 54.0 %\n",
      "\n",
      "Running model 176 out of 324\n",
      "Progress: 54.3 %\n",
      "\n",
      "Running model 177 out of 324\n",
      "Progress: 54.6 %\n",
      "\n",
      "Running model 178 out of 324\n",
      "Progress: 54.9 %\n",
      "\n",
      "Running model 179 out of 324\n",
      "Progress: 55.2 %\n",
      "\n",
      "Running model 180 out of 324\n",
      "Progress: 55.6 %\n",
      "\n",
      "Running model 181 out of 324\n",
      "Progress: 55.9 %\n",
      "\n",
      "Running model 182 out of 324\n",
      "Progress: 56.2 %\n",
      "\n",
      "Running model 183 out of 324\n",
      "Progress: 56.5 %\n",
      "\n",
      "Running model 184 out of 324\n",
      "Progress: 56.8 %\n",
      "\n",
      "Running model 185 out of 324\n",
      "Progress: 57.1 %\n",
      "\n",
      "Running model 186 out of 324\n",
      "Progress: 57.4 %\n",
      "\n",
      "Running model 187 out of 324\n",
      "Progress: 57.7 %\n",
      "\n",
      "Running model 188 out of 324\n",
      "Progress: 58.0 %\n",
      "\n",
      "Running model 189 out of 324\n",
      "Progress: 58.3 %\n",
      "\n",
      "Running model 190 out of 324\n",
      "Progress: 58.6 %\n",
      "\n",
      "Running model 191 out of 324\n",
      "Progress: 59.0 %\n",
      "\n",
      "Running model 192 out of 324\n",
      "Progress: 59.3 %\n",
      "\n",
      "Running model 193 out of 324\n",
      "Progress: 59.6 %\n",
      "\n",
      "Running model 194 out of 324\n",
      "Progress: 59.9 %\n",
      "\n",
      "Running model 195 out of 324\n",
      "Progress: 60.2 %\n",
      "\n",
      "Running model 196 out of 324\n",
      "Progress: 60.5 %\n",
      "\n",
      "Running model 197 out of 324\n",
      "Progress: 60.8 %\n",
      "\n",
      "Running model 198 out of 324\n",
      "Progress: 61.1 %\n",
      "\n",
      "Running model 199 out of 324\n",
      "Progress: 61.4 %\n",
      "\n",
      "Running model 200 out of 324\n",
      "Progress: 61.7 %\n",
      "\n",
      "Running model 201 out of 324\n",
      "Progress: 62.0 %\n",
      "\n",
      "Running model 202 out of 324\n",
      "Progress: 62.3 %\n",
      "\n",
      "Running model 203 out of 324\n",
      "Progress: 62.7 %\n",
      "\n",
      "Running model 204 out of 324\n",
      "Progress: 63.0 %\n",
      "\n",
      "Running model 205 out of 324\n",
      "Progress: 63.3 %\n",
      "\n",
      "Running model 206 out of 324\n",
      "Progress: 63.6 %\n",
      "\n",
      "Running model 207 out of 324\n",
      "Progress: 63.9 %\n",
      "\n",
      "Running model 208 out of 324\n",
      "Progress: 64.2 %\n",
      "\n",
      "Running model 209 out of 324\n",
      "Progress: 64.5 %\n",
      "\n",
      "Running model 210 out of 324\n",
      "Progress: 64.8 %\n",
      "\n",
      "Running model 211 out of 324\n",
      "Progress: 65.1 %\n",
      "\n",
      "Running model 212 out of 324\n",
      "Progress: 65.4 %\n",
      "\n",
      "Running model 213 out of 324\n",
      "Progress: 65.7 %\n",
      "\n",
      "Running model 214 out of 324\n",
      "Progress: 66.0 %\n",
      "\n",
      "Running model 215 out of 324\n",
      "Progress: 66.4 %\n",
      "\n",
      "Running model 216 out of 324\n",
      "Progress: 66.7 %\n",
      "Dataset: Holdout 1: 06/30/2012\n",
      "Predicting every data point's value to be 0, the accuracy is 74.3 %\n",
      "\n",
      "Running model 217 out of 324\n",
      "Progress: 67.0 %\n",
      "\n",
      "Running model 218 out of 324\n",
      "Progress: 67.3 %\n",
      "\n",
      "Running model 219 out of 324\n",
      "Progress: 67.6 %\n",
      "\n",
      "Running model 220 out of 324\n",
      "Progress: 67.9 %\n",
      "\n",
      "Running model 221 out of 324\n",
      "Progress: 68.2 %\n",
      "\n",
      "Running model 222 out of 324\n",
      "Progress: 68.5 %\n",
      "\n",
      "Running model 223 out of 324\n",
      "Progress: 68.8 %\n",
      "\n",
      "Running model 224 out of 324\n",
      "Progress: 69.1 %\n",
      "\n",
      "Running model 225 out of 324\n",
      "Progress: 69.4 %\n",
      "\n",
      "Running model 226 out of 324\n",
      "Progress: 69.8 %\n",
      "\n",
      "Running model 227 out of 324\n",
      "Progress: 70.1 %\n",
      "\n",
      "Running model 228 out of 324\n",
      "Progress: 70.4 %\n",
      "\n",
      "Running model 229 out of 324\n",
      "Progress: 70.7 %\n",
      "\n",
      "Running model 230 out of 324\n",
      "Progress: 71.0 %\n",
      "\n",
      "Running model 231 out of 324\n",
      "Progress: 71.3 %\n",
      "\n",
      "Running model 232 out of 324\n",
      "Progress: 71.6 %\n",
      "\n",
      "Running model 233 out of 324\n",
      "Progress: 71.9 %\n",
      "\n",
      "Running model 234 out of 324\n",
      "Progress: 72.2 %\n",
      "\n",
      "Running model 235 out of 324\n",
      "Progress: 72.5 %\n",
      "\n",
      "Running model 236 out of 324\n",
      "Progress: 72.8 %\n",
      "\n",
      "Running model 237 out of 324\n",
      "Progress: 73.1 %\n",
      "\n",
      "Running model 238 out of 324\n",
      "Progress: 73.5 %\n",
      "\n",
      "Running model 239 out of 324\n",
      "Progress: 73.8 %\n",
      "\n",
      "Running model 240 out of 324\n",
      "Progress: 74.1 %\n",
      "\n",
      "Running model 241 out of 324\n",
      "Progress: 74.4 %\n",
      "\n",
      "Running model 242 out of 324\n",
      "Progress: 74.7 %\n",
      "\n",
      "Running model 243 out of 324\n",
      "Progress: 75.0 %\n",
      "\n",
      "Running model 244 out of 324\n",
      "Progress: 75.3 %\n",
      "\n",
      "Running model 245 out of 324\n",
      "Progress: 75.6 %\n",
      "\n",
      "Running model 246 out of 324\n",
      "Progress: 75.9 %\n",
      "\n",
      "Running model 247 out of 324\n",
      "Progress: 76.2 %\n",
      "\n",
      "Running model 248 out of 324\n",
      "Progress: 76.5 %\n",
      "\n",
      "Running model 249 out of 324\n",
      "Progress: 76.9 %\n",
      "\n",
      "Running model 250 out of 324\n",
      "Progress: 77.2 %\n",
      "\n",
      "Running model 251 out of 324\n",
      "Progress: 77.5 %\n",
      "\n",
      "Running model 252 out of 324\n",
      "Progress: 77.8 %\n",
      "\n",
      "Running model 253 out of 324\n",
      "Progress: 78.1 %\n",
      "\n",
      "Running model 254 out of 324\n",
      "Progress: 78.4 %\n",
      "\n",
      "Running model 255 out of 324\n",
      "Progress: 78.7 %\n",
      "\n",
      "Running model 256 out of 324\n",
      "Progress: 79.0 %\n",
      "\n",
      "Running model 257 out of 324\n",
      "Progress: 79.3 %\n",
      "\n",
      "Running model 258 out of 324\n",
      "Progress: 79.6 %\n",
      "\n",
      "Running model 259 out of 324\n",
      "Progress: 79.9 %\n",
      "\n",
      "Running model 260 out of 324\n",
      "Progress: 80.2 %\n",
      "\n",
      "Running model 261 out of 324\n",
      "Progress: 80.6 %\n",
      "\n",
      "Running model 262 out of 324\n",
      "Progress: 80.9 %\n",
      "\n",
      "Running model 263 out of 324\n",
      "Progress: 81.2 %\n",
      "\n",
      "Running model 264 out of 324\n",
      "Progress: 81.5 %\n",
      "\n",
      "Running model 265 out of 324\n",
      "Progress: 81.8 %\n",
      "\n",
      "Running model 266 out of 324\n",
      "Progress: 82.1 %\n",
      "\n",
      "Running model 267 out of 324\n",
      "Progress: 82.4 %\n",
      "\n",
      "Running model 268 out of 324\n",
      "Progress: 82.7 %\n",
      "\n",
      "Running model 269 out of 324\n",
      "Progress: 83.0 %\n",
      "\n",
      "Running model 270 out of 324\n",
      "Progress: 83.3 %\n",
      "\n",
      "Running model 271 out of 324\n",
      "Progress: 83.6 %\n",
      "\n",
      "Running model 272 out of 324\n",
      "Progress: 84.0 %\n",
      "\n",
      "Running model 273 out of 324\n",
      "Progress: 84.3 %\n",
      "\n",
      "Running model 274 out of 324\n",
      "Progress: 84.6 %\n",
      "\n",
      "Running model 275 out of 324\n",
      "Progress: 84.9 %\n",
      "\n",
      "Running model 276 out of 324\n",
      "Progress: 85.2 %\n",
      "\n",
      "Running model 277 out of 324\n",
      "Progress: 85.5 %\n",
      "\n",
      "Running model 278 out of 324\n",
      "Progress: 85.8 %\n",
      "\n",
      "Running model 279 out of 324\n",
      "Progress: 86.1 %\n",
      "\n",
      "Running model 280 out of 324\n",
      "Progress: 86.4 %\n",
      "\n",
      "Running model 281 out of 324\n",
      "Progress: 86.7 %\n",
      "\n",
      "Running model 282 out of 324\n",
      "Progress: 87.0 %\n",
      "\n",
      "Running model 283 out of 324\n",
      "Progress: 87.3 %\n",
      "\n",
      "Running model 284 out of 324\n",
      "Progress: 87.7 %\n",
      "\n",
      "Running model 285 out of 324\n",
      "Progress: 88.0 %\n",
      "\n",
      "Running model 286 out of 324\n",
      "Progress: 88.3 %\n",
      "\n",
      "Running model 287 out of 324\n",
      "Progress: 88.6 %\n",
      "\n",
      "Running model 288 out of 324\n",
      "Progress: 88.9 %\n",
      "\n",
      "Running model 289 out of 324\n",
      "Progress: 89.2 %\n",
      "\n",
      "Running model 290 out of 324\n",
      "Progress: 89.5 %\n",
      "\n",
      "Running model 291 out of 324\n",
      "Progress: 89.8 %\n",
      "\n",
      "Running model 292 out of 324\n",
      "Progress: 90.1 %\n",
      "\n",
      "Running model 293 out of 324\n",
      "Progress: 90.4 %\n",
      "\n",
      "Running model 294 out of 324\n",
      "Progress: 90.7 %\n",
      "\n",
      "Running model 295 out of 324\n",
      "Progress: 91.0 %\n",
      "\n",
      "Running model 296 out of 324\n",
      "Progress: 91.4 %\n",
      "\n",
      "Running model 297 out of 324\n",
      "Progress: 91.7 %\n",
      "\n",
      "Running model 298 out of 324\n",
      "Progress: 92.0 %\n",
      "\n",
      "Running model 299 out of 324\n",
      "Progress: 92.3 %\n",
      "\n",
      "Running model 300 out of 324\n",
      "Progress: 92.6 %\n",
      "\n",
      "Running model 301 out of 324\n",
      "Progress: 92.9 %\n",
      "\n",
      "Running model 302 out of 324\n",
      "Progress: 93.2 %\n",
      "\n",
      "Running model 303 out of 324\n",
      "Progress: 93.5 %\n",
      "\n",
      "Running model 304 out of 324\n",
      "Progress: 93.8 %\n",
      "\n",
      "Running model 305 out of 324\n",
      "Progress: 94.1 %\n",
      "\n",
      "Running model 306 out of 324\n",
      "Progress: 94.4 %\n",
      "\n",
      "Running model 307 out of 324\n",
      "Progress: 94.8 %\n",
      "\n",
      "Running model 308 out of 324\n",
      "Progress: 95.1 %\n",
      "\n",
      "Running model 309 out of 324\n",
      "Progress: 95.4 %\n",
      "\n",
      "Running model 310 out of 324\n",
      "Progress: 95.7 %\n",
      "\n",
      "Running model 311 out of 324\n",
      "Progress: 96.0 %\n",
      "\n",
      "Running model 312 out of 324\n",
      "Progress: 96.3 %\n",
      "\n",
      "Running model 313 out of 324\n",
      "Progress: 96.6 %\n",
      "\n",
      "Running model 314 out of 324\n",
      "Progress: 96.9 %\n",
      "\n",
      "Running model 315 out of 324\n",
      "Progress: 97.2 %\n",
      "\n",
      "Running model 316 out of 324\n",
      "Progress: 97.5 %\n",
      "\n",
      "Running model 317 out of 324\n",
      "Progress: 97.8 %\n",
      "\n",
      "Running model 318 out of 324\n",
      "Progress: 98.1 %\n",
      "\n",
      "Running model 319 out of 324\n",
      "Progress: 98.5 %\n",
      "\n",
      "Running model 320 out of 324\n",
      "Progress: 98.8 %\n",
      "\n",
      "Running model 321 out of 324\n",
      "Progress: 99.1 %\n",
      "\n",
      "Running model 322 out of 324\n",
      "Progress: 99.4 %\n",
      "\n",
      "Running model 323 out of 324\n",
      "Progress: 99.7 %\n",
      "\n",
      "Running model 324 out of 324\n",
      "Progress: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "table = pipeline.evaluation_table(pipeline.CLASSIFIERS, pipeline.PARAMETERS_MID, datasets, fractions, features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exact classifier</th>\n",
       "      <th>classifier</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dataset</th>\n",
       "      <th>baseline</th>\n",
       "      <th>precision_at_0.01</th>\n",
       "      <th>precision_at_0.02</th>\n",
       "      <th>precision_at_0.05</th>\n",
       "      <th>precision_at_0.1</th>\n",
       "      <th>precision_at_0.2</th>\n",
       "      <th>precision_at_0.3</th>\n",
       "      <th>precision_at_0.5</th>\n",
       "      <th>recall_at_0.01</th>\n",
       "      <th>recall_at_0.02</th>\n",
       "      <th>recall_at_0.05</th>\n",
       "      <th>recall_at_0.1</th>\n",
       "      <th>recall_at_0.2</th>\n",
       "      <th>recall_at_0.3</th>\n",
       "      <th>recall_at_0.5</th>\n",
       "      <th>AUC ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.516279</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>0.527340</td>\n",
       "      <td>0.518536</td>\n",
       "      <td>0.481584</td>\n",
       "      <td>0.450502</td>\n",
       "      <td>0.415678</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>0.083701</td>\n",
       "      <td>0.164607</td>\n",
       "      <td>0.305825</td>\n",
       "      <td>0.429097</td>\n",
       "      <td>0.659900</td>\n",
       "      <td>0.659041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.576744</td>\n",
       "      <td>0.538283</td>\n",
       "      <td>0.533828</td>\n",
       "      <td>0.527340</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0.458069</td>\n",
       "      <td>0.423925</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>0.034128</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.167402</td>\n",
       "      <td>0.310827</td>\n",
       "      <td>0.436305</td>\n",
       "      <td>0.672992</td>\n",
       "      <td>0.669567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.483721</td>\n",
       "      <td>0.480278</td>\n",
       "      <td>0.481001</td>\n",
       "      <td>0.478684</td>\n",
       "      <td>0.472319</td>\n",
       "      <td>0.446178</td>\n",
       "      <td>0.413176</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.030450</td>\n",
       "      <td>0.076346</td>\n",
       "      <td>0.151956</td>\n",
       "      <td>0.299941</td>\n",
       "      <td>0.424978</td>\n",
       "      <td>0.655928</td>\n",
       "      <td>0.654921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.553488</td>\n",
       "      <td>0.501160</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>0.525023</td>\n",
       "      <td>0.485522</td>\n",
       "      <td>0.449421</td>\n",
       "      <td>0.423832</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.083407</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.308326</td>\n",
       "      <td>0.428067</td>\n",
       "      <td>0.672845</td>\n",
       "      <td>0.667621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.493023</td>\n",
       "      <td>0.459397</td>\n",
       "      <td>0.487488</td>\n",
       "      <td>0.515755</td>\n",
       "      <td>0.443595</td>\n",
       "      <td>0.433668</td>\n",
       "      <td>0.411694</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.077376</td>\n",
       "      <td>0.163725</td>\n",
       "      <td>0.281701</td>\n",
       "      <td>0.413063</td>\n",
       "      <td>0.653575</td>\n",
       "      <td>0.652081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.545244</td>\n",
       "      <td>0.516219</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>0.495251</td>\n",
       "      <td>0.451892</td>\n",
       "      <td>0.424574</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.034569</td>\n",
       "      <td>0.081936</td>\n",
       "      <td>0.166814</td>\n",
       "      <td>0.314504</td>\n",
       "      <td>0.430421</td>\n",
       "      <td>0.674022</td>\n",
       "      <td>0.669523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.455814</td>\n",
       "      <td>0.498840</td>\n",
       "      <td>0.502317</td>\n",
       "      <td>0.483318</td>\n",
       "      <td>0.495946</td>\n",
       "      <td>0.451274</td>\n",
       "      <td>0.413454</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>0.079729</td>\n",
       "      <td>0.153427</td>\n",
       "      <td>0.314946</td>\n",
       "      <td>0.429832</td>\n",
       "      <td>0.656370</td>\n",
       "      <td>0.660362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.535963</td>\n",
       "      <td>0.497683</td>\n",
       "      <td>0.519462</td>\n",
       "      <td>0.486449</td>\n",
       "      <td>0.450965</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.078994</td>\n",
       "      <td>0.164901</td>\n",
       "      <td>0.308914</td>\n",
       "      <td>0.429538</td>\n",
       "      <td>0.668432</td>\n",
       "      <td>0.666117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.483721</td>\n",
       "      <td>0.512761</td>\n",
       "      <td>0.515292</td>\n",
       "      <td>0.494903</td>\n",
       "      <td>0.482511</td>\n",
       "      <td>0.453745</td>\n",
       "      <td>0.417346</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>0.081789</td>\n",
       "      <td>0.157105</td>\n",
       "      <td>0.306414</td>\n",
       "      <td>0.432186</td>\n",
       "      <td>0.662548</td>\n",
       "      <td>0.661887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.586047</td>\n",
       "      <td>0.549884</td>\n",
       "      <td>0.557924</td>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.496641</td>\n",
       "      <td>0.468417</td>\n",
       "      <td>0.426798</td>\n",
       "      <td>0.018535</td>\n",
       "      <td>0.034863</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>0.165637</td>\n",
       "      <td>0.315387</td>\n",
       "      <td>0.446161</td>\n",
       "      <td>0.677552</td>\n",
       "      <td>0.677530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.520930</td>\n",
       "      <td>0.508121</td>\n",
       "      <td>0.491196</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.456104</td>\n",
       "      <td>0.443707</td>\n",
       "      <td>0.419570</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.077964</td>\n",
       "      <td>0.146514</td>\n",
       "      <td>0.289644</td>\n",
       "      <td>0.422624</td>\n",
       "      <td>0.666078</td>\n",
       "      <td>0.659736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.576744</td>\n",
       "      <td>0.568445</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.527340</td>\n",
       "      <td>0.495946</td>\n",
       "      <td>0.470270</td>\n",
       "      <td>0.429670</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>0.167402</td>\n",
       "      <td>0.314946</td>\n",
       "      <td>0.447926</td>\n",
       "      <td>0.682112</td>\n",
       "      <td>0.680383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.545244</td>\n",
       "      <td>0.557924</td>\n",
       "      <td>0.535681</td>\n",
       "      <td>0.492472</td>\n",
       "      <td>0.468417</td>\n",
       "      <td>0.421609</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>0.034569</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>0.170050</td>\n",
       "      <td>0.312739</td>\n",
       "      <td>0.446161</td>\n",
       "      <td>0.669315</td>\n",
       "      <td>0.670784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.568445</td>\n",
       "      <td>0.565338</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.472741</td>\n",
       "      <td>0.429207</td>\n",
       "      <td>0.018388</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.089732</td>\n",
       "      <td>0.168285</td>\n",
       "      <td>0.316858</td>\n",
       "      <td>0.450279</td>\n",
       "      <td>0.681377</td>\n",
       "      <td>0.680792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.510441</td>\n",
       "      <td>0.485635</td>\n",
       "      <td>0.468489</td>\n",
       "      <td>0.440584</td>\n",
       "      <td>0.419768</td>\n",
       "      <td>0.407339</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.077081</td>\n",
       "      <td>0.148720</td>\n",
       "      <td>0.279788</td>\n",
       "      <td>0.399823</td>\n",
       "      <td>0.646661</td>\n",
       "      <td>0.643361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.617169</td>\n",
       "      <td>0.564411</td>\n",
       "      <td>0.537998</td>\n",
       "      <td>0.504749</td>\n",
       "      <td>0.473359</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.089585</td>\n",
       "      <td>0.170786</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.450868</td>\n",
       "      <td>0.680936</td>\n",
       "      <td>0.680411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.501160</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.455978</td>\n",
       "      <td>0.417883</td>\n",
       "      <td>0.390734</td>\n",
       "      <td>0.387139</td>\n",
       "      <td>0.016917</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.073404</td>\n",
       "      <td>0.144748</td>\n",
       "      <td>0.265372</td>\n",
       "      <td>0.372168</td>\n",
       "      <td>0.614593</td>\n",
       "      <td>0.626179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.540603</td>\n",
       "      <td>0.529194</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>0.465833</td>\n",
       "      <td>0.446950</td>\n",
       "      <td>0.417161</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.083995</td>\n",
       "      <td>0.166814</td>\n",
       "      <td>0.295822</td>\n",
       "      <td>0.425713</td>\n",
       "      <td>0.662254</td>\n",
       "      <td>0.662772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.553488</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>0.560704</td>\n",
       "      <td>0.528730</td>\n",
       "      <td>0.499884</td>\n",
       "      <td>0.466718</td>\n",
       "      <td>0.416976</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.167843</td>\n",
       "      <td>0.317446</td>\n",
       "      <td>0.444543</td>\n",
       "      <td>0.661959</td>\n",
       "      <td>0.663084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.522042</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.527340</td>\n",
       "      <td>0.486449</td>\n",
       "      <td>0.455290</td>\n",
       "      <td>0.424481</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>0.033098</td>\n",
       "      <td>0.082230</td>\n",
       "      <td>0.167402</td>\n",
       "      <td>0.308914</td>\n",
       "      <td>0.433657</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.668121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.595349</td>\n",
       "      <td>0.582367</td>\n",
       "      <td>0.556070</td>\n",
       "      <td>0.528730</td>\n",
       "      <td>0.475793</td>\n",
       "      <td>0.453591</td>\n",
       "      <td>0.387880</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.088261</td>\n",
       "      <td>0.167843</td>\n",
       "      <td>0.302148</td>\n",
       "      <td>0.432039</td>\n",
       "      <td>0.615769</td>\n",
       "      <td>0.648997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.526682</td>\n",
       "      <td>0.529194</td>\n",
       "      <td>0.521316</td>\n",
       "      <td>0.485754</td>\n",
       "      <td>0.454208</td>\n",
       "      <td>0.418643</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.033392</td>\n",
       "      <td>0.083995</td>\n",
       "      <td>0.165490</td>\n",
       "      <td>0.308473</td>\n",
       "      <td>0.432627</td>\n",
       "      <td>0.664607</td>\n",
       "      <td>0.664048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.489559</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.497683</td>\n",
       "      <td>0.495946</td>\n",
       "      <td>0.445405</td>\n",
       "      <td>0.406227</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>0.078405</td>\n",
       "      <td>0.157988</td>\n",
       "      <td>0.314946</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.644896</td>\n",
       "      <td>0.655128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.572093</td>\n",
       "      <td>0.531323</td>\n",
       "      <td>0.519926</td>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.494325</td>\n",
       "      <td>0.452355</td>\n",
       "      <td>0.425408</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>0.033686</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>0.165637</td>\n",
       "      <td>0.313916</td>\n",
       "      <td>0.430862</td>\n",
       "      <td>0.675346</td>\n",
       "      <td>0.668830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>0.497683</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.432476</td>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.386953</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>0.032068</td>\n",
       "      <td>0.078994</td>\n",
       "      <td>0.145337</td>\n",
       "      <td>0.274640</td>\n",
       "      <td>0.390262</td>\n",
       "      <td>0.614298</td>\n",
       "      <td>0.617182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.618605</td>\n",
       "      <td>0.600928</td>\n",
       "      <td>0.559778</td>\n",
       "      <td>0.519462</td>\n",
       "      <td>0.488534</td>\n",
       "      <td>0.467027</td>\n",
       "      <td>0.423369</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>0.088850</td>\n",
       "      <td>0.164901</td>\n",
       "      <td>0.310238</td>\n",
       "      <td>0.444837</td>\n",
       "      <td>0.672109</td>\n",
       "      <td>0.673135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.535963</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>0.503244</td>\n",
       "      <td>0.475793</td>\n",
       "      <td>0.451737</td>\n",
       "      <td>0.416049</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.082377</td>\n",
       "      <td>0.159753</td>\n",
       "      <td>0.302148</td>\n",
       "      <td>0.430274</td>\n",
       "      <td>0.660488</td>\n",
       "      <td>0.660050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.572093</td>\n",
       "      <td>0.577726</td>\n",
       "      <td>0.559778</td>\n",
       "      <td>0.528730</td>\n",
       "      <td>0.502896</td>\n",
       "      <td>0.468726</td>\n",
       "      <td>0.428744</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>0.036628</td>\n",
       "      <td>0.088850</td>\n",
       "      <td>0.167843</td>\n",
       "      <td>0.319359</td>\n",
       "      <td>0.446455</td>\n",
       "      <td>0.680641</td>\n",
       "      <td>0.679898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 10, 'n_jobs': 10, 'max_sample...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.548837</td>\n",
       "      <td>0.563805</td>\n",
       "      <td>0.535681</td>\n",
       "      <td>0.509731</td>\n",
       "      <td>0.483438</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.416234</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.035746</td>\n",
       "      <td>0.085025</td>\n",
       "      <td>0.161812</td>\n",
       "      <td>0.307002</td>\n",
       "      <td>0.435863</td>\n",
       "      <td>0.660783</td>\n",
       "      <td>0.664109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BaggingClassifier(base_estimator=DecisionTreeC...</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'n_estimators': 100, 'n_jobs': 10, 'max_sampl...</td>\n",
       "      <td>Holdout 2: 12/31/2012</td>\n",
       "      <td>0.685059</td>\n",
       "      <td>0.618605</td>\n",
       "      <td>0.600928</td>\n",
       "      <td>0.571826</td>\n",
       "      <td>0.533364</td>\n",
       "      <td>0.503590</td>\n",
       "      <td>0.474595</td>\n",
       "      <td>0.430504</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>0.090762</td>\n",
       "      <td>0.169315</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>0.452045</td>\n",
       "      <td>0.683436</td>\n",
       "      <td>0.681672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=1.0, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>0.241221</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0.250534</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.257960</td>\n",
       "      <td>0.253830</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>0.097552</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=0.1, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>0.241221</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0.250534</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.257960</td>\n",
       "      <td>0.253830</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>0.097552</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=0.1, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>0.241221</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0.250534</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.257960</td>\n",
       "      <td>0.253830</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>0.097552</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=0.1, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>0.241221</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0.250534</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.257960</td>\n",
       "      <td>0.253830</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>0.097552</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=1.0, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.432061</td>\n",
       "      <td>0.416972</td>\n",
       "      <td>0.419591</td>\n",
       "      <td>0.400214</td>\n",
       "      <td>0.380938</td>\n",
       "      <td>0.350320</td>\n",
       "      <td>0.016754</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.081155</td>\n",
       "      <td>0.163379</td>\n",
       "      <td>0.311668</td>\n",
       "      <td>0.444986</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>0.663808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=1.0, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.434251</td>\n",
       "      <td>0.432061</td>\n",
       "      <td>0.427961</td>\n",
       "      <td>0.418065</td>\n",
       "      <td>0.397772</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.349222</td>\n",
       "      <td>0.016873</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.083294</td>\n",
       "      <td>0.162785</td>\n",
       "      <td>0.309767</td>\n",
       "      <td>0.444510</td>\n",
       "      <td>0.679895</td>\n",
       "      <td>0.663867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=1.0, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.480122</td>\n",
       "      <td>0.454962</td>\n",
       "      <td>0.438950</td>\n",
       "      <td>0.421727</td>\n",
       "      <td>0.398840</td>\n",
       "      <td>0.381650</td>\n",
       "      <td>0.349039</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>0.035409</td>\n",
       "      <td>0.085433</td>\n",
       "      <td>0.164211</td>\n",
       "      <td>0.310599</td>\n",
       "      <td>0.445817</td>\n",
       "      <td>0.679539</td>\n",
       "      <td>0.663795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=0.1, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.418960</td>\n",
       "      <td>0.430534</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.404333</td>\n",
       "      <td>0.380226</td>\n",
       "      <td>0.363137</td>\n",
       "      <td>0.336588</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.033508</td>\n",
       "      <td>0.081274</td>\n",
       "      <td>0.157438</td>\n",
       "      <td>0.296103</td>\n",
       "      <td>0.424192</td>\n",
       "      <td>0.655299</td>\n",
       "      <td>0.638697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=0.1, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.428135</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>0.420024</td>\n",
       "      <td>0.411352</td>\n",
       "      <td>0.391211</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.342630</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>0.081749</td>\n",
       "      <td>0.160171</td>\n",
       "      <td>0.304658</td>\n",
       "      <td>0.434648</td>\n",
       "      <td>0.667063</td>\n",
       "      <td>0.650944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME.R',\\n     ...</td>\n",
       "      <td>Ada boosting</td>\n",
       "      <td>{'base_estimator': LogisticRegression(C=0.1, c...</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.429008</td>\n",
       "      <td>0.414530</td>\n",
       "      <td>0.418676</td>\n",
       "      <td>0.394263</td>\n",
       "      <td>0.379717</td>\n",
       "      <td>0.347208</td>\n",
       "      <td>0.017110</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.080680</td>\n",
       "      <td>0.163023</td>\n",
       "      <td>0.307034</td>\n",
       "      <td>0.443560</td>\n",
       "      <td>0.675974</td>\n",
       "      <td>0.659745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>LinearSVC(C=0.001, class_weight=None, dual=Fal...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l1', 'dual': False, 'C': 0.001}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.446483</td>\n",
       "      <td>0.415267</td>\n",
       "      <td>0.392552</td>\n",
       "      <td>0.375648</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.372393</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>0.017348</td>\n",
       "      <td>0.032319</td>\n",
       "      <td>0.076402</td>\n",
       "      <td>0.146269</td>\n",
       "      <td>0.297291</td>\n",
       "      <td>0.435005</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.649735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>LinearSVC(C=0.001, class_weight=None, dual=Fal...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l2', 'dual': False, 'C': 0.001}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.498471</td>\n",
       "      <td>0.462595</td>\n",
       "      <td>0.442002</td>\n",
       "      <td>0.419591</td>\n",
       "      <td>0.402807</td>\n",
       "      <td>0.382871</td>\n",
       "      <td>0.350198</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>0.036003</td>\n",
       "      <td>0.086027</td>\n",
       "      <td>0.163379</td>\n",
       "      <td>0.313688</td>\n",
       "      <td>0.447243</td>\n",
       "      <td>0.681797</td>\n",
       "      <td>0.665375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>LinearSVC(C=0.01, class_weight=None, dual=Fals...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l1', 'dual': False, 'C': 0.01}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.489297</td>\n",
       "      <td>0.464122</td>\n",
       "      <td>0.443223</td>\n",
       "      <td>0.422032</td>\n",
       "      <td>0.404486</td>\n",
       "      <td>0.382667</td>\n",
       "      <td>0.348734</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.036122</td>\n",
       "      <td>0.086264</td>\n",
       "      <td>0.164330</td>\n",
       "      <td>0.314995</td>\n",
       "      <td>0.447006</td>\n",
       "      <td>0.678945</td>\n",
       "      <td>0.663013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>LinearSVC(C=0.01, class_weight=None, dual=Fals...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l2', 'dual': False, 'C': 0.01}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.507645</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.429792</td>\n",
       "      <td>0.418370</td>\n",
       "      <td>0.400061</td>\n",
       "      <td>0.383786</td>\n",
       "      <td>0.351480</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>0.038023</td>\n",
       "      <td>0.083650</td>\n",
       "      <td>0.162904</td>\n",
       "      <td>0.311549</td>\n",
       "      <td>0.448313</td>\n",
       "      <td>0.684292</td>\n",
       "      <td>0.662783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>LinearSVC(C=0.1, class_weight=None, dual=False...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l1', 'dual': False, 'C': 0.1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>0.431013</td>\n",
       "      <td>0.411962</td>\n",
       "      <td>0.398078</td>\n",
       "      <td>0.381650</td>\n",
       "      <td>0.349954</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.037429</td>\n",
       "      <td>0.083888</td>\n",
       "      <td>0.160409</td>\n",
       "      <td>0.310005</td>\n",
       "      <td>0.445817</td>\n",
       "      <td>0.681321</td>\n",
       "      <td>0.661109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>LinearSVC(C=0.1, class_weight=None, dual=False...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l2', 'dual': False, 'C': 0.1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.429792</td>\n",
       "      <td>0.409826</td>\n",
       "      <td>0.397315</td>\n",
       "      <td>0.381446</td>\n",
       "      <td>0.349527</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.083650</td>\n",
       "      <td>0.159577</td>\n",
       "      <td>0.309411</td>\n",
       "      <td>0.445580</td>\n",
       "      <td>0.680490</td>\n",
       "      <td>0.660088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>LinearSVC(C=1, class_weight=None, dual=False, ...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l1', 'dual': False, 'C': 1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.467176</td>\n",
       "      <td>0.430403</td>\n",
       "      <td>0.411047</td>\n",
       "      <td>0.396857</td>\n",
       "      <td>0.381650</td>\n",
       "      <td>0.349710</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.036359</td>\n",
       "      <td>0.083769</td>\n",
       "      <td>0.160052</td>\n",
       "      <td>0.309054</td>\n",
       "      <td>0.445817</td>\n",
       "      <td>0.680846</td>\n",
       "      <td>0.659776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>LinearSVC(C=1, class_weight=None, dual=False, ...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l2', 'dual': False, 'C': 1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.465649</td>\n",
       "      <td>0.429182</td>\n",
       "      <td>0.410436</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.381040</td>\n",
       "      <td>0.349283</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.036240</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.159815</td>\n",
       "      <td>0.308817</td>\n",
       "      <td>0.445105</td>\n",
       "      <td>0.680014</td>\n",
       "      <td>0.659588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=False,...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l1', 'dual': False, 'C': 10}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.465649</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.410742</td>\n",
       "      <td>0.396704</td>\n",
       "      <td>0.381040</td>\n",
       "      <td>0.349283</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.036240</td>\n",
       "      <td>0.083413</td>\n",
       "      <td>0.159933</td>\n",
       "      <td>0.308935</td>\n",
       "      <td>0.445105</td>\n",
       "      <td>0.680014</td>\n",
       "      <td>0.659562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=False,...</td>\n",
       "      <td>Support vector machine</td>\n",
       "      <td>{'penalty': 'l2', 'dual': False, 'C': 10}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.464122</td>\n",
       "      <td>0.427961</td>\n",
       "      <td>0.410436</td>\n",
       "      <td>0.396857</td>\n",
       "      <td>0.380938</td>\n",
       "      <td>0.349222</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.036122</td>\n",
       "      <td>0.083294</td>\n",
       "      <td>0.159815</td>\n",
       "      <td>0.309054</td>\n",
       "      <td>0.444986</td>\n",
       "      <td>0.679895</td>\n",
       "      <td>0.659535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>LogisticRegression(C=0.001, class_weight=None,...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.001}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>0.241221</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0.250534</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.257960</td>\n",
       "      <td>0.253830</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.018774</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>0.097552</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>LogisticRegression(C=0.001, class_weight=None,...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.001}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.418960</td>\n",
       "      <td>0.450382</td>\n",
       "      <td>0.416361</td>\n",
       "      <td>0.424168</td>\n",
       "      <td>0.399756</td>\n",
       "      <td>0.381040</td>\n",
       "      <td>0.349771</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>0.081036</td>\n",
       "      <td>0.165162</td>\n",
       "      <td>0.311312</td>\n",
       "      <td>0.445105</td>\n",
       "      <td>0.680965</td>\n",
       "      <td>0.662661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.01}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.391437</td>\n",
       "      <td>0.383206</td>\n",
       "      <td>0.390110</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.387702</td>\n",
       "      <td>0.377174</td>\n",
       "      <td>0.342997</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.029824</td>\n",
       "      <td>0.075927</td>\n",
       "      <td>0.155062</td>\n",
       "      <td>0.301925</td>\n",
       "      <td>0.440589</td>\n",
       "      <td>0.667776</td>\n",
       "      <td>0.655329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.01}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.489297</td>\n",
       "      <td>0.464122</td>\n",
       "      <td>0.438950</td>\n",
       "      <td>0.419896</td>\n",
       "      <td>0.402350</td>\n",
       "      <td>0.383583</td>\n",
       "      <td>0.350137</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.036122</td>\n",
       "      <td>0.085433</td>\n",
       "      <td>0.163498</td>\n",
       "      <td>0.313332</td>\n",
       "      <td>0.448075</td>\n",
       "      <td>0.681678</td>\n",
       "      <td>0.665116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.501529</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.443834</td>\n",
       "      <td>0.415319</td>\n",
       "      <td>0.401434</td>\n",
       "      <td>0.382057</td>\n",
       "      <td>0.349283</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.086383</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>0.312619</td>\n",
       "      <td>0.446293</td>\n",
       "      <td>0.680014</td>\n",
       "      <td>0.662880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>0.497710</td>\n",
       "      <td>0.429792</td>\n",
       "      <td>0.412572</td>\n",
       "      <td>0.398078</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.349832</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.038736</td>\n",
       "      <td>0.083650</td>\n",
       "      <td>0.160646</td>\n",
       "      <td>0.310005</td>\n",
       "      <td>0.445936</td>\n",
       "      <td>0.681084</td>\n",
       "      <td>0.662463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>LogisticRegression(C=1, class_weight=None, dua...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l1', 'C': 1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.501529</td>\n",
       "      <td>0.477863</td>\n",
       "      <td>0.430403</td>\n",
       "      <td>0.408911</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.381345</td>\n",
       "      <td>0.349222</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>0.037191</td>\n",
       "      <td>0.083769</td>\n",
       "      <td>0.159221</td>\n",
       "      <td>0.308817</td>\n",
       "      <td>0.445461</td>\n",
       "      <td>0.679895</td>\n",
       "      <td>0.659509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>LogisticRegression(C=1, class_weight=None, dua...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.498471</td>\n",
       "      <td>0.479389</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.407690</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.380938</td>\n",
       "      <td>0.348612</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>0.037310</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.158745</td>\n",
       "      <td>0.308817</td>\n",
       "      <td>0.444986</td>\n",
       "      <td>0.678707</td>\n",
       "      <td>0.659482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l1', 'C': 10}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.474809</td>\n",
       "      <td>0.429182</td>\n",
       "      <td>0.406774</td>\n",
       "      <td>0.396247</td>\n",
       "      <td>0.380938</td>\n",
       "      <td>0.348428</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.158389</td>\n",
       "      <td>0.308579</td>\n",
       "      <td>0.444986</td>\n",
       "      <td>0.678351</td>\n",
       "      <td>0.658865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>{'penalty': 'l2', 'C': 10}</td>\n",
       "      <td>Holdout 1: 06/30/2012</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.501529</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.407080</td>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.381040</td>\n",
       "      <td>0.348367</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.083413</td>\n",
       "      <td>0.158508</td>\n",
       "      <td>0.308698</td>\n",
       "      <td>0.445105</td>\n",
       "      <td>0.678232</td>\n",
       "      <td>0.658860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Exact classifier  \\\n",
       "0    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "1    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "2    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "3    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "4    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "5    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "6    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "7    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "8    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "9    BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "10   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "11   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "12   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "13   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "14   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "15   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "16   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "17   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "18   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "19   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "20   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "21   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "22   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "23   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "24   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "25   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "26   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "27   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "28   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "29   BaggingClassifier(base_estimator=DecisionTreeC...   \n",
       "..                                                 ...   \n",
       "294  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "295  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "296  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "297  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "298  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "299  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "300  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "301  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "302  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "303  AdaBoostClassifier(algorithm='SAMME.R',\\n     ...   \n",
       "304  LinearSVC(C=0.001, class_weight=None, dual=Fal...   \n",
       "305  LinearSVC(C=0.001, class_weight=None, dual=Fal...   \n",
       "306  LinearSVC(C=0.01, class_weight=None, dual=Fals...   \n",
       "307  LinearSVC(C=0.01, class_weight=None, dual=Fals...   \n",
       "308  LinearSVC(C=0.1, class_weight=None, dual=False...   \n",
       "309  LinearSVC(C=0.1, class_weight=None, dual=False...   \n",
       "310  LinearSVC(C=1, class_weight=None, dual=False, ...   \n",
       "311  LinearSVC(C=1, class_weight=None, dual=False, ...   \n",
       "312  LinearSVC(C=10, class_weight=None, dual=False,...   \n",
       "313  LinearSVC(C=10, class_weight=None, dual=False,...   \n",
       "314  LogisticRegression(C=0.001, class_weight=None,...   \n",
       "315  LogisticRegression(C=0.001, class_weight=None,...   \n",
       "316  LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "317  LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "318  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "319  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "320  LogisticRegression(C=1, class_weight=None, dua...   \n",
       "321  LogisticRegression(C=1, class_weight=None, dua...   \n",
       "322  LogisticRegression(C=10, class_weight=None, du...   \n",
       "323  LogisticRegression(C=10, class_weight=None, du...   \n",
       "\n",
       "                 classifier  \\\n",
       "0                   Bagging   \n",
       "1                   Bagging   \n",
       "2                   Bagging   \n",
       "3                   Bagging   \n",
       "4                   Bagging   \n",
       "5                   Bagging   \n",
       "6                   Bagging   \n",
       "7                   Bagging   \n",
       "8                   Bagging   \n",
       "9                   Bagging   \n",
       "10                  Bagging   \n",
       "11                  Bagging   \n",
       "12                  Bagging   \n",
       "13                  Bagging   \n",
       "14                  Bagging   \n",
       "15                  Bagging   \n",
       "16                  Bagging   \n",
       "17                  Bagging   \n",
       "18                  Bagging   \n",
       "19                  Bagging   \n",
       "20                  Bagging   \n",
       "21                  Bagging   \n",
       "22                  Bagging   \n",
       "23                  Bagging   \n",
       "24                  Bagging   \n",
       "25                  Bagging   \n",
       "26                  Bagging   \n",
       "27                  Bagging   \n",
       "28                  Bagging   \n",
       "29                  Bagging   \n",
       "..                      ...   \n",
       "294            Ada boosting   \n",
       "295            Ada boosting   \n",
       "296            Ada boosting   \n",
       "297            Ada boosting   \n",
       "298            Ada boosting   \n",
       "299            Ada boosting   \n",
       "300            Ada boosting   \n",
       "301            Ada boosting   \n",
       "302            Ada boosting   \n",
       "303            Ada boosting   \n",
       "304  Support vector machine   \n",
       "305  Support vector machine   \n",
       "306  Support vector machine   \n",
       "307  Support vector machine   \n",
       "308  Support vector machine   \n",
       "309  Support vector machine   \n",
       "310  Support vector machine   \n",
       "311  Support vector machine   \n",
       "312  Support vector machine   \n",
       "313  Support vector machine   \n",
       "314     Logistic regression   \n",
       "315     Logistic regression   \n",
       "316     Logistic regression   \n",
       "317     Logistic regression   \n",
       "318     Logistic regression   \n",
       "319     Logistic regression   \n",
       "320     Logistic regression   \n",
       "321     Logistic regression   \n",
       "322     Logistic regression   \n",
       "323     Logistic regression   \n",
       "\n",
       "                                            parameters                dataset  \\\n",
       "0    {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "1    {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "2    {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "3    {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "4    {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "5    {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "6    {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "7    {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "8    {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "9    {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "10   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "11   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "12   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "13   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "14   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "15   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "16   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "17   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "18   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "19   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "20   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "21   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "22   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "23   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "24   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "25   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "26   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "27   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "28   {'n_estimators': 10, 'n_jobs': 10, 'max_sample...  Holdout 2: 12/31/2012   \n",
       "29   {'n_estimators': 100, 'n_jobs': 10, 'max_sampl...  Holdout 2: 12/31/2012   \n",
       "..                                                 ...                    ...   \n",
       "294  {'base_estimator': LogisticRegression(C=1.0, c...  Holdout 1: 06/30/2012   \n",
       "295  {'base_estimator': LogisticRegression(C=0.1, c...  Holdout 1: 06/30/2012   \n",
       "296  {'base_estimator': LogisticRegression(C=0.1, c...  Holdout 1: 06/30/2012   \n",
       "297  {'base_estimator': LogisticRegression(C=0.1, c...  Holdout 1: 06/30/2012   \n",
       "298  {'base_estimator': LogisticRegression(C=1.0, c...  Holdout 1: 06/30/2012   \n",
       "299  {'base_estimator': LogisticRegression(C=1.0, c...  Holdout 1: 06/30/2012   \n",
       "300  {'base_estimator': LogisticRegression(C=1.0, c...  Holdout 1: 06/30/2012   \n",
       "301  {'base_estimator': LogisticRegression(C=0.1, c...  Holdout 1: 06/30/2012   \n",
       "302  {'base_estimator': LogisticRegression(C=0.1, c...  Holdout 1: 06/30/2012   \n",
       "303  {'base_estimator': LogisticRegression(C=0.1, c...  Holdout 1: 06/30/2012   \n",
       "304       {'penalty': 'l1', 'dual': False, 'C': 0.001}  Holdout 1: 06/30/2012   \n",
       "305       {'penalty': 'l2', 'dual': False, 'C': 0.001}  Holdout 1: 06/30/2012   \n",
       "306        {'penalty': 'l1', 'dual': False, 'C': 0.01}  Holdout 1: 06/30/2012   \n",
       "307        {'penalty': 'l2', 'dual': False, 'C': 0.01}  Holdout 1: 06/30/2012   \n",
       "308         {'penalty': 'l1', 'dual': False, 'C': 0.1}  Holdout 1: 06/30/2012   \n",
       "309         {'penalty': 'l2', 'dual': False, 'C': 0.1}  Holdout 1: 06/30/2012   \n",
       "310           {'penalty': 'l1', 'dual': False, 'C': 1}  Holdout 1: 06/30/2012   \n",
       "311           {'penalty': 'l2', 'dual': False, 'C': 1}  Holdout 1: 06/30/2012   \n",
       "312          {'penalty': 'l1', 'dual': False, 'C': 10}  Holdout 1: 06/30/2012   \n",
       "313          {'penalty': 'l2', 'dual': False, 'C': 10}  Holdout 1: 06/30/2012   \n",
       "314                      {'penalty': 'l1', 'C': 0.001}  Holdout 1: 06/30/2012   \n",
       "315                      {'penalty': 'l2', 'C': 0.001}  Holdout 1: 06/30/2012   \n",
       "316                       {'penalty': 'l1', 'C': 0.01}  Holdout 1: 06/30/2012   \n",
       "317                       {'penalty': 'l2', 'C': 0.01}  Holdout 1: 06/30/2012   \n",
       "318                        {'penalty': 'l1', 'C': 0.1}  Holdout 1: 06/30/2012   \n",
       "319                        {'penalty': 'l2', 'C': 0.1}  Holdout 1: 06/30/2012   \n",
       "320                          {'penalty': 'l1', 'C': 1}  Holdout 1: 06/30/2012   \n",
       "321                          {'penalty': 'l2', 'C': 1}  Holdout 1: 06/30/2012   \n",
       "322                         {'penalty': 'l1', 'C': 10}  Holdout 1: 06/30/2012   \n",
       "323                         {'penalty': 'l2', 'C': 10}  Holdout 1: 06/30/2012   \n",
       "\n",
       "     baseline  precision_at_0.01  precision_at_0.02  precision_at_0.05  \\\n",
       "0    0.685059           0.516279           0.554524           0.527340   \n",
       "1    0.685059           0.576744           0.538283           0.533828   \n",
       "2    0.685059           0.483721           0.480278           0.481001   \n",
       "3    0.685059           0.553488           0.501160           0.525487   \n",
       "4    0.685059           0.493023           0.459397           0.487488   \n",
       "5    0.685059           0.511628           0.545244           0.516219   \n",
       "6    0.685059           0.455814           0.498840           0.502317   \n",
       "7    0.685059           0.530233           0.535963           0.497683   \n",
       "8    0.685059           0.483721           0.512761           0.515292   \n",
       "9    0.685059           0.586047           0.549884           0.557924   \n",
       "10   0.685059           0.520930           0.508121           0.491196   \n",
       "11   0.685059           0.576744           0.568445           0.554217   \n",
       "12   0.685059           0.604651           0.545244           0.557924   \n",
       "13   0.685059           0.581395           0.568445           0.565338   \n",
       "14   0.685059           0.539535           0.510441           0.485635   \n",
       "15   0.685059           0.637209           0.617169           0.564411   \n",
       "16   0.685059           0.534884           0.501160           0.462465   \n",
       "17   0.685059           0.530233           0.540603           0.529194   \n",
       "18   0.685059           0.553488           0.554524           0.560704   \n",
       "19   0.685059           0.567442           0.522042           0.518072   \n",
       "20   0.685059           0.595349           0.582367           0.556070   \n",
       "21   0.685059           0.530233           0.526682           0.529194   \n",
       "22   0.685059           0.479070           0.489559           0.493976   \n",
       "23   0.685059           0.572093           0.531323           0.519926   \n",
       "24   0.685059           0.525581           0.505800           0.497683   \n",
       "25   0.685059           0.618605           0.600928           0.559778   \n",
       "26   0.685059           0.511628           0.535963           0.518999   \n",
       "27   0.685059           0.572093           0.577726           0.559778   \n",
       "28   0.685059           0.548837           0.563805           0.535681   \n",
       "29   0.685059           0.618605           0.600928           0.571826   \n",
       "..        ...                ...                ...                ...   \n",
       "294  0.743188           0.217125           0.241221           0.254579   \n",
       "295  0.743188           0.217125           0.241221           0.254579   \n",
       "296  0.743188           0.217125           0.241221           0.254579   \n",
       "297  0.743188           0.217125           0.241221           0.254579   \n",
       "298  0.743188           0.431193           0.432061           0.416972   \n",
       "299  0.743188           0.434251           0.432061           0.427961   \n",
       "300  0.743188           0.480122           0.454962           0.438950   \n",
       "301  0.743188           0.418960           0.430534           0.417582   \n",
       "302  0.743188           0.428135           0.427481           0.420024   \n",
       "303  0.743188           0.440367           0.429008           0.414530   \n",
       "304  0.743188           0.446483           0.415267           0.392552   \n",
       "305  0.743188           0.498471           0.462595           0.442002   \n",
       "306  0.743188           0.489297           0.464122           0.443223   \n",
       "307  0.743188           0.507645           0.488550           0.429792   \n",
       "308  0.743188           0.513761           0.480916           0.431013   \n",
       "309  0.743188           0.486239           0.473282           0.429792   \n",
       "310  0.743188           0.483180           0.467176           0.430403   \n",
       "311  0.743188           0.483180           0.465649           0.429182   \n",
       "312  0.743188           0.483180           0.465649           0.428571   \n",
       "313  0.743188           0.483180           0.464122           0.427961   \n",
       "314  0.743188           0.217125           0.241221           0.254579   \n",
       "315  0.743188           0.418960           0.450382           0.416361   \n",
       "316  0.743188           0.391437           0.383206           0.390110   \n",
       "317  0.743188           0.489297           0.464122           0.438950   \n",
       "318  0.743188           0.501529           0.473282           0.443834   \n",
       "319  0.743188           0.513761           0.497710           0.429792   \n",
       "320  0.743188           0.501529           0.477863           0.430403   \n",
       "321  0.743188           0.498471           0.479389           0.427350   \n",
       "322  0.743188           0.504587           0.474809           0.429182   \n",
       "323  0.743188           0.501529           0.473282           0.428571   \n",
       "\n",
       "     precision_at_0.1  precision_at_0.2  precision_at_0.3  precision_at_0.5  \\\n",
       "0            0.518536          0.481584          0.450502          0.415678   \n",
       "1            0.527340          0.489460          0.458069          0.423925   \n",
       "2            0.478684          0.472319          0.446178          0.413176   \n",
       "3            0.525023          0.485522          0.449421          0.423832   \n",
       "4            0.515755          0.443595          0.433668          0.411694   \n",
       "5            0.525487          0.495251          0.451892          0.424574   \n",
       "6            0.483318          0.495946          0.451274          0.413454   \n",
       "7            0.519462          0.486449          0.450965          0.421053   \n",
       "8            0.494903          0.482511          0.453745          0.417346   \n",
       "9            0.521779          0.496641          0.468417          0.426798   \n",
       "10           0.461538          0.456104          0.443707          0.419570   \n",
       "11           0.527340          0.495946          0.470270          0.429670   \n",
       "12           0.535681          0.492472          0.468417          0.421609   \n",
       "13           0.530120          0.498958          0.472741          0.429207   \n",
       "14           0.468489          0.440584          0.419768          0.407339   \n",
       "15           0.537998          0.504749          0.473359          0.428929   \n",
       "16           0.455978          0.417883          0.390734          0.387139   \n",
       "17           0.525487          0.465833          0.446950          0.417161   \n",
       "18           0.528730          0.499884          0.466718          0.416976   \n",
       "19           0.527340          0.486449          0.455290          0.424481   \n",
       "20           0.528730          0.475793          0.453591          0.387880   \n",
       "21           0.521316          0.485754          0.454208          0.418643   \n",
       "22           0.497683          0.495946          0.445405          0.406227   \n",
       "23           0.521779          0.494325          0.452355          0.425408   \n",
       "24           0.457831          0.432476          0.409730          0.386953   \n",
       "25           0.519462          0.488534          0.467027          0.423369   \n",
       "26           0.503244          0.475793          0.451737          0.416049   \n",
       "27           0.528730          0.502896          0.468726          0.428744   \n",
       "28           0.509731          0.483438          0.457606          0.416234   \n",
       "29           0.533364          0.503590          0.474595          0.430504   \n",
       "..                ...               ...               ...               ...   \n",
       "294          0.250534          0.252670          0.257960          0.253830   \n",
       "295          0.250534          0.252670          0.257960          0.253830   \n",
       "296          0.250534          0.252670          0.257960          0.253830   \n",
       "297          0.250534          0.252670          0.257960          0.253830   \n",
       "298          0.419591          0.400214          0.380938          0.350320   \n",
       "299          0.418065          0.397772          0.380531          0.349222   \n",
       "300          0.421727          0.398840          0.381650          0.349039   \n",
       "301          0.404333          0.380226          0.363137          0.336588   \n",
       "302          0.411352          0.391211          0.372088          0.342630   \n",
       "303          0.418676          0.394263          0.379717          0.347208   \n",
       "304          0.375648          0.381752          0.372393          0.337077   \n",
       "305          0.419591          0.402807          0.382871          0.350198   \n",
       "306          0.422032          0.404486          0.382667          0.348734   \n",
       "307          0.418370          0.400061          0.383786          0.351480   \n",
       "308          0.411962          0.398078          0.381650          0.349954   \n",
       "309          0.409826          0.397315          0.381446          0.349527   \n",
       "310          0.411047          0.396857          0.381650          0.349710   \n",
       "311          0.410436          0.396552          0.381040          0.349283   \n",
       "312          0.410742          0.396704          0.381040          0.349283   \n",
       "313          0.410436          0.396857          0.380938          0.349222   \n",
       "314          0.250534          0.252670          0.257960          0.253830   \n",
       "315          0.424168          0.399756          0.381040          0.349771   \n",
       "316          0.398230          0.387702          0.377174          0.342997   \n",
       "317          0.419896          0.402350          0.383583          0.350137   \n",
       "318          0.415319          0.401434          0.382057          0.349283   \n",
       "319          0.412572          0.398078          0.381752          0.349832   \n",
       "320          0.408911          0.396552          0.381345          0.349222   \n",
       "321          0.407690          0.396552          0.380938          0.348612   \n",
       "322          0.406774          0.396247          0.380938          0.348428   \n",
       "323          0.407080          0.396399          0.381040          0.348367   \n",
       "\n",
       "     recall_at_0.01  recall_at_0.02  recall_at_0.05  recall_at_0.1  \\\n",
       "0          0.016328        0.035157        0.083701       0.164607   \n",
       "1          0.018241        0.034128        0.084731       0.167402   \n",
       "2          0.015299        0.030450        0.076346       0.151956   \n",
       "3          0.017505        0.031774        0.083407       0.166667   \n",
       "4          0.015593        0.029126        0.077376       0.163725   \n",
       "5          0.016181        0.034569        0.081936       0.166814   \n",
       "6          0.014416        0.031627        0.079729       0.153427   \n",
       "7          0.016770        0.033981        0.078994       0.164901   \n",
       "8          0.015299        0.032510        0.081789       0.157105   \n",
       "9          0.018535        0.034863        0.088555       0.165637   \n",
       "10         0.016475        0.032215        0.077964       0.146514   \n",
       "11         0.018241        0.036040        0.087967       0.167402   \n",
       "12         0.019123        0.034569        0.088555       0.170050   \n",
       "13         0.018388        0.036040        0.089732       0.168285   \n",
       "14         0.017064        0.032362        0.077081       0.148720   \n",
       "15         0.020153        0.039129        0.089585       0.170786   \n",
       "16         0.016917        0.031774        0.073404       0.144748   \n",
       "17         0.016770        0.034275        0.083995       0.166814   \n",
       "18         0.017505        0.035157        0.088997       0.167843   \n",
       "19         0.017946        0.033098        0.082230       0.167402   \n",
       "20         0.018829        0.036923        0.088261       0.167843   \n",
       "21         0.016770        0.033392        0.083995       0.165490   \n",
       "22         0.015152        0.031039        0.078405       0.157988   \n",
       "23         0.018094        0.033686        0.082524       0.165637   \n",
       "24         0.016623        0.032068        0.078994       0.145337   \n",
       "25         0.019565        0.038099        0.088850       0.164901   \n",
       "26         0.016181        0.033981        0.082377       0.159753   \n",
       "27         0.018094        0.036628        0.088850       0.167843   \n",
       "28         0.017358        0.035746        0.085025       0.161812   \n",
       "29         0.019565        0.038099        0.090762       0.169315   \n",
       "..              ...             ...             ...            ...   \n",
       "294        0.008436        0.018774        0.049548       0.097552   \n",
       "295        0.008436        0.018774        0.049548       0.097552   \n",
       "296        0.008436        0.018774        0.049548       0.097552   \n",
       "297        0.008436        0.018774        0.049548       0.097552   \n",
       "298        0.016754        0.033626        0.081155       0.163379   \n",
       "299        0.016873        0.033626        0.083294       0.162785   \n",
       "300        0.018655        0.035409        0.085433       0.164211   \n",
       "301        0.016279        0.033508        0.081274       0.157438   \n",
       "302        0.016635        0.033270        0.081749       0.160171   \n",
       "303        0.017110        0.033389        0.080680       0.163023   \n",
       "304        0.017348        0.032319        0.076402       0.146269   \n",
       "305        0.019368        0.036003        0.086027       0.163379   \n",
       "306        0.019011        0.036122        0.086264       0.164330   \n",
       "307        0.019724        0.038023        0.083650       0.162904   \n",
       "308        0.019962        0.037429        0.083888       0.160409   \n",
       "309        0.018893        0.036835        0.083650       0.159577   \n",
       "310        0.018774        0.036359        0.083769       0.160052   \n",
       "311        0.018774        0.036240        0.083531       0.159815   \n",
       "312        0.018774        0.036240        0.083413       0.159933   \n",
       "313        0.018774        0.036122        0.083294       0.159815   \n",
       "314        0.008436        0.018774        0.049548       0.097552   \n",
       "315        0.016279        0.035052        0.081036       0.165162   \n",
       "316        0.015209        0.029824        0.075927       0.155062   \n",
       "317        0.019011        0.036122        0.085433       0.163498   \n",
       "318        0.019487        0.036835        0.086383       0.161716   \n",
       "319        0.019962        0.038736        0.083650       0.160646   \n",
       "320        0.019487        0.037191        0.083769       0.159221   \n",
       "321        0.019368        0.037310        0.083175       0.158745   \n",
       "322        0.019606        0.036953        0.083531       0.158389   \n",
       "323        0.019487        0.036835        0.083413       0.158508   \n",
       "\n",
       "     recall_at_0.2  recall_at_0.3  recall_at_0.5   AUC ROC  \n",
       "0         0.305825       0.429097       0.659900  0.659041  \n",
       "1         0.310827       0.436305       0.672992  0.669567  \n",
       "2         0.299941       0.424978       0.655928  0.654921  \n",
       "3         0.308326       0.428067       0.672845  0.667621  \n",
       "4         0.281701       0.413063       0.653575  0.652081  \n",
       "5         0.314504       0.430421       0.674022  0.669523  \n",
       "6         0.314946       0.429832       0.656370  0.660362  \n",
       "7         0.308914       0.429538       0.668432  0.666117  \n",
       "8         0.306414       0.432186       0.662548  0.661887  \n",
       "9         0.315387       0.446161       0.677552  0.677530  \n",
       "10        0.289644       0.422624       0.666078  0.659736  \n",
       "11        0.314946       0.447926       0.682112  0.680383  \n",
       "12        0.312739       0.446161       0.669315  0.670784  \n",
       "13        0.316858       0.450279       0.681377  0.680792  \n",
       "14        0.279788       0.399823       0.646661  0.643361  \n",
       "15        0.320535       0.450868       0.680936  0.680411  \n",
       "16        0.265372       0.372168       0.614593  0.626179  \n",
       "17        0.295822       0.425713       0.662254  0.662772  \n",
       "18        0.317446       0.444543       0.661959  0.663084  \n",
       "19        0.308914       0.433657       0.673875  0.668121  \n",
       "20        0.302148       0.432039       0.615769  0.648997  \n",
       "21        0.308473       0.432627       0.664607  0.664048  \n",
       "22        0.314946       0.424242       0.644896  0.655128  \n",
       "23        0.313916       0.430862       0.675346  0.668830  \n",
       "24        0.274640       0.390262       0.614298  0.617182  \n",
       "25        0.310238       0.444837       0.672109  0.673135  \n",
       "26        0.302148       0.430274       0.660488  0.660050  \n",
       "27        0.319359       0.446455       0.680641  0.679898  \n",
       "28        0.307002       0.435863       0.660783  0.664109  \n",
       "29        0.319800       0.452045       0.683436  0.681672  \n",
       "..             ...            ...            ...       ...  \n",
       "294       0.196768       0.301331       0.494178  0.500000  \n",
       "295       0.196768       0.301331       0.494178  0.500000  \n",
       "296       0.196768       0.301331       0.494178  0.500000  \n",
       "297       0.196768       0.301331       0.494178  0.500000  \n",
       "298       0.311668       0.444986       0.682034  0.663808  \n",
       "299       0.309767       0.444510       0.679895  0.663867  \n",
       "300       0.310599       0.445817       0.679539  0.663795  \n",
       "301       0.296103       0.424192       0.655299  0.638697  \n",
       "302       0.304658       0.434648       0.667063  0.650944  \n",
       "303       0.307034       0.443560       0.675974  0.659745  \n",
       "304       0.297291       0.435005       0.656250  0.649735  \n",
       "305       0.313688       0.447243       0.681797  0.665375  \n",
       "306       0.314995       0.447006       0.678945  0.663013  \n",
       "307       0.311549       0.448313       0.684292  0.662783  \n",
       "308       0.310005       0.445817       0.681321  0.661109  \n",
       "309       0.309411       0.445580       0.680490  0.660088  \n",
       "310       0.309054       0.445817       0.680846  0.659776  \n",
       "311       0.308817       0.445105       0.680014  0.659588  \n",
       "312       0.308935       0.445105       0.680014  0.659562  \n",
       "313       0.309054       0.444986       0.679895  0.659535  \n",
       "314       0.196768       0.301331       0.494178  0.500000  \n",
       "315       0.311312       0.445105       0.680965  0.662661  \n",
       "316       0.301925       0.440589       0.667776  0.655329  \n",
       "317       0.313332       0.448075       0.681678  0.665116  \n",
       "318       0.312619       0.446293       0.680014  0.662880  \n",
       "319       0.310005       0.445936       0.681084  0.662463  \n",
       "320       0.308817       0.445461       0.679895  0.659509  \n",
       "321       0.308817       0.444986       0.678707  0.659482  \n",
       "322       0.308579       0.444986       0.678351  0.658865  \n",
       "323       0.308698       0.445105       0.678232  0.658860  \n",
       "\n",
       "[324 rows x 20 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('evaluation_table.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
