{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding writeup\n",
    "\n",
    "Author: Luis Eduardo \"Luise\" San Martin\n",
    "\n",
    "This writeup explains and goes through my solutions for the coding tasks in the Assignment 3.\n",
    "\n",
    "## Coding\n",
    "\n",
    "1. Fix and improve the pipeline code you submitted for the last assignment based on the feedback from the TA. if something critical was pointed out in the feedback, you need to fix it.\n",
    "\n",
    "**Finished:** What my code missed was adding the pipeline functions used in actual functions, instead of running them directly in my Jupyter Notebook writeup. This is now corrected in the files `exploration.py`, `preparation.py`, `classifiers.py` and `evaluation.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add more classifiers to the pipeline. It should at least have Logistic Regression, K-Nearest Neighbor, Decision Trees, SVM, Random Forests, Boosting, and Bagging. The code should have a parameter for running one or more of these classifiers and your analysis should run all of them.\n",
    "\n",
    "**Finished:** Added more classifiers. They are in the file `classifiers.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Experiment with different parameters for these classifiers (different values of k for example, as well as parameters that other classifiers have). You should look at the sklearn documentation to see what parameter each classifier can take and what the default values sklearn selects. The labs should be helpful here.\n",
    "\n",
    "**Finished:** Function parameters thar are passed into the classifiers have been added for all the classifier functions included in `classifiers.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add additional evaluation metrics that we've covered in class to the pipeline (accuracy, precision at different levels, recall at different levels, F1, area under curve, and precision-recall curves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create temporal validation function in your pipeline that can create training and test sets over time. You can choose the length of these splits based on analyzing the data. For example, the test sets could be six months long and the training sets could be all the data before each test set.\n",
    "\n",
    "**Finished:** This function has been defined in the script `preparation.py`. The function name is `time_based_split`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
